{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args <__main__.Args object at 0x7f1470341278>\n",
      "<class 'self_aug.autoaug_scripts.Augmentation'>\n",
      "HELLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-04 21:58:59,600\tINFO resource_spec.py:212 -- Starting Ray with 791.99 GiB memory available for workers and up to 186.26 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-04 21:59:00,098\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/1005.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/28 CPUs, 1/2 GPUs, 0.0/791.99 GiB heap, 0.0/128.52 GiB objects<br>Result logdir: /home/smetzger/ray_results/slm_moco_min_debug_ICL_rot_search_cifar10_fold_0<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  level_0_0</th><th style=\"text-align: right;\">  level_0_1</th><th style=\"text-align: right;\">  level_1_0</th><th style=\"text-align: right;\">  level_1_1</th><th style=\"text-align: right;\">  level_2_0</th><th style=\"text-align: right;\">  level_2_1</th><th style=\"text-align: right;\">  level_3_0</th><th style=\"text-align: right;\">  level_3_1</th><th style=\"text-align: right;\">  level_4_0</th><th style=\"text-align: right;\">  level_4_1</th><th style=\"text-align: right;\">  policy_0_0</th><th style=\"text-align: right;\">  policy_0_1</th><th style=\"text-align: right;\">  policy_1_0</th><th style=\"text-align: right;\">  policy_1_1</th><th style=\"text-align: right;\">  policy_2_0</th><th style=\"text-align: right;\">  policy_2_1</th><th style=\"text-align: right;\">  policy_3_0</th><th style=\"text-align: right;\">  policy_3_1</th><th style=\"text-align: right;\">  policy_4_0</th><th style=\"text-align: right;\">  policy_4_1</th><th style=\"text-align: right;\">  prob_0_0</th><th style=\"text-align: right;\">  prob_0_1</th><th style=\"text-align: right;\">  prob_1_0</th><th style=\"text-align: right;\">  prob_1_1</th><th style=\"text-align: right;\">  prob_2_0</th><th style=\"text-align: right;\">  prob_2_1</th><th style=\"text-align: right;\">  prob_3_0</th><th style=\"text-align: right;\">  prob_3_1</th><th style=\"text-align: right;\">  prob_4_0</th><th style=\"text-align: right;\">  prob_4_1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>eval_augmentations_223dca46</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.137366</td><td style=\"text-align: right;\">   0.341002</td><td style=\"text-align: right;\">0.000371775</td><td style=\"text-align: right;\">   0.762402</td><td style=\"text-align: right;\">   0.180757</td><td style=\"text-align: right;\">   0.998544</td><td style=\"text-align: right;\">   0.183576</td><td style=\"text-align: right;\">   0.635572</td><td style=\"text-align: right;\">   0.720283</td><td style=\"text-align: right;\">   0.669572</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\"> 0.0263224</td><td style=\"text-align: right;\">  0.186488</td><td style=\"text-align: right;\">  0.924366</td><td style=\"text-align: right;\">  0.331785</td><td style=\"text-align: right;\">   0.26434</td><td style=\"text-align: right;\">  0.219713</td><td style=\"text-align: right;\">   0.28301</td><td style=\"text-align: right;\">  0.217997</td><td style=\"text-align: right;\">  0.445516</td><td style=\"text-align: right;\">  0.191275</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m 2020-05-04 21:59:02,463\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m <class 'self_aug.autoaug_scripts.Augmentation'>\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m called {'num_op': 2, 'num_policy': 5, 'cv_fold': 0, 'level_0_0': 0.13736643949105665, 'level_0_1': 0.3410021825167293, 'level_1_0': 0.00037177450002978674, 'level_1_1': 0.7624018653771936, 'level_2_0': 0.18075673372290968, 'level_2_1': 0.9985440419453097, 'level_3_0': 0.18357642398336926, 'level_3_1': 0.6355715265856489, 'level_4_0': 0.7202826424743012, 'level_4_1': 0.6695717055301164, 'policy_0_0': 13, 'policy_0_1': 1, 'policy_1_0': 4, 'policy_1_1': 7, 'policy_2_0': 12, 'policy_2_1': 7, 'policy_3_0': 9, 'policy_3_1': 3, 'policy_4_0': 2, 'policy_4_1': 5, 'prob_0_0': 0.026322412076597357, 'prob_0_1': 0.18648755793115468, 'prob_1_0': 0.9243660702974643, 'prob_1_1': 0.33178477651968585, 'prob_2_0': 0.26433961973440157, 'prob_2_1': 0.2197128508774353, 'prob_3_0': 0.2830095731218212, 'prob_3_1': 0.21799727074039044, 'prob_4_0': 0.44551581612475766, 'prob_4_1': 0.19127492098954912}\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m icl\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m HELLO\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.30859375\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.302734375\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.3001302083333333\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.291015625\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.291015625\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2890625\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29380580357142855\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29345703125\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2953559027777778\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29453125\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2959872159090909\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.30029296875\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29837740384615385\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29813058035714285\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2975260416666667\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2960205078125\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.29607077205882354\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2957899305555556\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (2560,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 512)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 512\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2948190789473684\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (1360,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 272)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 272\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.2948\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m rotation\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m HELLO\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.13786520584329348\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct -0.03064699205448354\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.05073092170465808\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.11516051011433596\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.16595849802371543\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.207735104091888\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.24256245890861275\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.27251364463311095\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.29762239729881823\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.320505249343832\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.33952287260206593\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.35637436372049974\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.3712865880297073\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.38555026892842365\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.39776522593320235\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.4089272353161242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.4176856479828633\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.42597729600546264\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (10240,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 2048)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 2048\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.43251144913313705\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m l shape (5440,)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m corrects shape (5, 1088)\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m len c max 1088\n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m correct 0.43664\n",
      "Result for eval_augmentations_223dca46:\n",
      "  date: 2020-05-04_22-00-48\n",
      "  done: false\n",
      "  experiment_id: 29092aaa1b2d4bf4b18adf1c86d1ce43\n",
      "  experiment_tag: 1_cv_fold=0,level_0_0=0.13737,level_0_1=0.341,level_1_0=0.00037177,level_1_1=0.7624,level_2_0=0.18076,level_2_1=0.99854,level_3_0=0.18358,level_3_1=0.63557,level_4_0=0.72028,level_4_1=0.66957,num_op=2,num_policy=5,policy_0_0=13,policy_0_1=1,policy_1_0=4,policy_1_1=7,policy_2_0=12,policy_2_1=7,policy_3_0=9,policy_3_1=3,policy_4_0=2,policy_4_1=5,prob_0_0=0.026322,prob_0_1=0.18649,prob_1_0=0.92437,prob_1_1=0.33178,prob_2_0=0.26434,prob_2_1=0.21971,prob_3_0=0.28301,prob_3_1=0.218,prob_4_0=0.44552,prob_4_1=0.19127\n",
      "  hostname: spirit\n",
      "  iterations_since_restore: 1\n",
      "  minus_loss: 1.444112851333618\n",
      "  node_ip: 169.230.190.118\n",
      "  pid: 77365\n",
      "  plus_loss: -0.9095346740722656\n",
      "  time_since_restore: 106.50054860115051\n",
      "  time_this_iter_s: 106.50054860115051\n",
      "  time_total_s: 106.50054860115051\n",
      "  timestamp: 1588654848\n",
      "  timesteps_since_restore: 0\n",
      "  top_1_valid: 0.43664\n",
      "  training_iteration: 0\n",
      "  trial_id: 223dca46\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=77365)\u001b[0m 0.43664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/1005.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/28 CPUs, 1/2 GPUs, 0.0/791.99 GiB heap, 0.0/128.52 GiB objects<br>Result logdir: /home/smetzger/ray_results/slm_moco_min_debug_ICL_rot_search_cifar10_fold_0<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  level_0_0</th><th style=\"text-align: right;\">  level_0_1</th><th style=\"text-align: right;\">  level_1_0</th><th style=\"text-align: right;\">  level_1_1</th><th style=\"text-align: right;\">  level_2_0</th><th style=\"text-align: right;\">  level_2_1</th><th style=\"text-align: right;\">  level_3_0</th><th style=\"text-align: right;\">  level_3_1</th><th style=\"text-align: right;\">  level_4_0</th><th style=\"text-align: right;\">  level_4_1</th><th style=\"text-align: right;\">  policy_0_0</th><th style=\"text-align: right;\">  policy_0_1</th><th style=\"text-align: right;\">  policy_1_0</th><th style=\"text-align: right;\">  policy_1_1</th><th style=\"text-align: right;\">  policy_2_0</th><th style=\"text-align: right;\">  policy_2_1</th><th style=\"text-align: right;\">  policy_3_0</th><th style=\"text-align: right;\">  policy_3_1</th><th style=\"text-align: right;\">  policy_4_0</th><th style=\"text-align: right;\">  policy_4_1</th><th style=\"text-align: right;\">  prob_0_0</th><th style=\"text-align: right;\">  prob_0_1</th><th style=\"text-align: right;\">  prob_1_0</th><th style=\"text-align: right;\">  prob_1_1</th><th style=\"text-align: right;\">  prob_2_0</th><th style=\"text-align: right;\">  prob_2_1</th><th style=\"text-align: right;\">  prob_3_0</th><th style=\"text-align: right;\">  prob_3_1</th><th style=\"text-align: right;\">  prob_4_0</th><th style=\"text-align: right;\">  prob_4_1</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>eval_augmentations_223dca46</td><td>RUNNING </td><td>169.230.190.118:77365</td><td style=\"text-align: right;\">   0.137366</td><td style=\"text-align: right;\">   0.341002</td><td style=\"text-align: right;\">0.000371775</td><td style=\"text-align: right;\">   0.762402</td><td style=\"text-align: right;\">   0.180757</td><td style=\"text-align: right;\">   0.998544</td><td style=\"text-align: right;\">   0.183576</td><td style=\"text-align: right;\">   0.635572</td><td style=\"text-align: right;\">   0.720283</td><td style=\"text-align: right;\">   0.669572</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\"> 0.0263224</td><td style=\"text-align: right;\">  0.186488</td><td style=\"text-align: right;\">  0.924366</td><td style=\"text-align: right;\">  0.331785</td><td style=\"text-align: right;\">   0.26434</td><td style=\"text-align: right;\">  0.219713</td><td style=\"text-align: right;\">   0.28301</td><td style=\"text-align: right;\">  0.217997</td><td style=\"text-align: right;\">  0.445516</td><td style=\"text-align: right;\">  0.191275</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">         106.501</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m <class 'self_aug.autoaug_scripts.Augmentation'>\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m called {'num_op': 2, 'num_policy': 5, 'cv_fold': 0, 'level_0_0': 0.9161250319062556, 'level_0_1': 0.21861892449055975, 'level_1_0': 0.3202392608340582, 'level_1_1': 0.28033756075881655, 'level_2_0': 0.4057128761487814, 'level_2_1': 0.20377549750596968, 'level_3_0': 0.6128446444092451, 'level_3_1': 0.4031296746168037, 'level_4_0': 0.3402201435616916, 'level_4_1': 0.48659263438762346, 'policy_0_0': 7, 'policy_0_1': 5, 'policy_1_0': 11, 'policy_1_1': 1, 'policy_2_0': 14, 'policy_2_1': 2, 'policy_3_0': 8, 'policy_3_1': 5, 'policy_4_0': 11, 'policy_4_1': 4, 'prob_0_0': 0.27707212682436666, 'prob_0_1': 0.276722345365387, 'prob_1_0': 0.4410052815138834, 'prob_1_1': 0.8664367136566624, 'prob_2_0': 0.2864768336802429, 'prob_2_1': 0.5522680530800581, 'prob_3_0': 0.7222911854894943, 'prob_3_1': 0.018497970054392687, 'prob_4_0': 0.09179629228648967, 'prob_4_1': 0.43711243034861413}\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m icl\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m HELLO\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m 2020-05-04 22:00:50,782\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=77370)\u001b[0m Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e195a94cd672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    505\u001b[0m             },\n\u001b[1;32m    506\u001b[0m             \u001b[0mreturn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training_iteration'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         )\n\u001b[1;32m    509\u001b[0m         \u001b[0mresults_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m         )\n\u001b[1;32m   1655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CODE is based of fastautoagument code here \n",
    "\n",
    "# https://github.com/kakaobrain/fast-autoaugment/blob/master/FastAutoAugment/search.py\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import ray \n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import track\n",
    "\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "from ray.tune import register_trainable, run_experiments\n",
    "import wandb\n",
    "import argparse\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/userdata/smetzger/all_deepul_files/deepul_proj/moco/\")\n",
    "import moco.loader\n",
    "import moco.builder\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "import os\n",
    "import ray.tune as tune\n",
    "\n",
    "\n",
    "\n",
    "# FOR DEBUG\n",
    "class Args:\n",
    "    checkpoints = ['fxrZE', 'lJu2W', 'rdEIg', 'esdq2' ,'vnhKs'] # Ordered KFOLDS order. Make this nicer.\n",
    "    checkpoint_fp = '/userdata/smetzger/all_deepul_files/ckpts'\n",
    "    data = '/userdata/smetzger/data/cifar_10/'\n",
    "    \n",
    "    # Some args for the Fast Autoaugment thing. \n",
    "    num_op = 2\n",
    "    num_policy=5\n",
    "    num_search = 200\n",
    "    dataid = 'cifar10'\n",
    "    cv_ratio=1.0\n",
    "    smoke_test=False\n",
    "    resume=False\n",
    "    arch = 'resnet50'\n",
    "    distributed=False\n",
    "    loss = 'icl_and_rotation'# one of rotation, supervised, icl, icl_and_rotation.\n",
    "    base = 'moco' # Name for what we are saving our training runs as.\n",
    "\n",
    "    # Moco args. \n",
    "    moco_k = 65536\n",
    "    moco_m = 0.999\n",
    "    moco_t = 0.2\n",
    "    \n",
    "    \n",
    "    # Whether or not to use the MLP for mocov2\n",
    "    mlp = True\n",
    "    \n",
    "    # Model input args for building the model head. \n",
    "    nomoco = False\n",
    "    rotnet = False\n",
    "    \n",
    "    moco_dim = 128\n",
    "    policy_dir = '/userdata/smetzger/all_deepul_files/policies'\n",
    "    \n",
    "    # Remember we are trying to max negative loss, so a negative here\n",
    "    # is like maximizing, a positive here is like minimizing. \n",
    "    loss_weights = {'rotation': 1, 'icl': -1, 'supervised':1} # weight for ICL, and ROTATION.\n",
    "\n",
    "    \n",
    "args=Args()\n",
    "print('args', args)\n",
    "\n",
    "import random\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.transforms import Compose\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "random_mirror = True\n",
    "from self_aug.autoaug_scripts import augment_list, Augmentation, Accumulator\n",
    "\n",
    "# Define how we load our dataloaders. \n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "def get_dataloaders(augmentations, batch=1024, kfold=0, loss_type='icl', get_train=False):\n",
    "\n",
    "    \"\"\"\n",
    "    input: augmentations: the list of the augmentations you want applied to the data. \n",
    "    batch = batchsize, \n",
    "    kfold, which fold you want to look at (0, 1,2 3, or 4)\n",
    "    get_train, whether or not you want the train data. Use this when loading the data to train linear classifiers, \n",
    "    slash when you're loading the final classifier. \n",
    "    \"\"\"\n",
    "    if args.dataid == \"imagenet\":\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            traindir,\n",
    "            transformations)\n",
    "\n",
    "        # TODO: add imagenet transforms etc. \n",
    "    elif args.dataid == \"cifar10\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "        \n",
    "        if loss_type == \"icl\": \n",
    "            \n",
    "            random_resized_crop = transforms.RandomResizedCrop(28, scale=(0.2, 1.))\n",
    "            \n",
    "            transform_train = transforms.Compose([\n",
    "            random_resized_crop,\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "            ])\n",
    "            \n",
    "        transform_train.transforms.insert(0, Augmentation(augmentations))\n",
    "        \n",
    "        \n",
    "        if loss_type == \"icl\": \n",
    "            transform_train = moco.loader.TwoCropsTransform(transform_train)\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Support for the following dataset is not yet implemented: {}\".format(args.dataid))\n",
    "\n",
    "    if get_train: \n",
    "        train_dataset = torchvision.datasets.CIFAR10(args.data,\n",
    "                                                     transform=transform_train,\n",
    "                                                     download=True)\n",
    "\n",
    "    # NOTE THAT IN THE FAA PAPER THE USED TRANSFORM TRAIN.  \n",
    "    \n",
    "    \n",
    "    val_dataset = torchvision.datasets.CIFAR10(args.data, transform=transform_train, \n",
    "        download=True)\n",
    "    \n",
    "\n",
    "    if get_train: \n",
    "        torch.manual_seed(1337)\n",
    "        lengths = [len(train_dataset)//5]*5\n",
    "        folds = torch.utils.data.random_split(train_dataset, lengths)\n",
    "        folds.pop(kfold)\n",
    "        train_dataset = torch.utils.data.ConcatDataset(folds)\n",
    "\n",
    "\n",
    "    torch.manual_seed(1337)\n",
    "    lengths = [len(val_dataset)//5]*5\n",
    "    folds = torch.utils.data.random_split(val_dataset, lengths)\n",
    "    val_dataset = folds[kfold]\n",
    "\n",
    "    if get_train: \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch, shuffle=(train_sampler is None),\n",
    "            num_workers=8, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "        \n",
    "    if loss_type == 'icl': \n",
    "        sampler =None\n",
    "        drop_last=False\n",
    "    else: \n",
    "        sampler =None\n",
    "        drop_last=False\n",
    "\n",
    "    val_loader= torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch, shuffle=True,\n",
    "        num_workers=4, pin_memory=True, drop_last=drop_last, \n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    if not get_train: \n",
    "        train_loader = None\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Take in the augment from hyperopt and return some augmentations, in teh way that we want them. \n",
    "def policy_decoder(augment, num_policy, num_op):\n",
    "    op_list = augment_list(False)\n",
    "    policies = []\n",
    "    for i in range(num_policy):\n",
    "        ops = []\n",
    "        for j in range(num_op):\n",
    "            op_idx = augment['policy_%d_%d' % (i, j)]\n",
    "            op_prob = augment['prob_%d_%d' % (i, j)]\n",
    "            op_level = augment['level_%d_%d' % (i, j)]\n",
    "            ops.append((op_list[op_idx][0].__name__, op_prob, op_level))\n",
    "        policies.append(ops)\n",
    "    return policies\n",
    "\n",
    "def find_model(name, fold, epochs=750, basepath=\"/userdata/smetzger/all_deepul_files/ckpts\"):\n",
    "    \"\"\"\n",
    "    name = model name\n",
    "    fold = which fold of the data to find. \n",
    "    epochs = how many epochs to load the checkpoint at (e.g. 750)\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in os.listdir(basepath):\n",
    "        if name in str(file) and 'fold_%d' %fold in str(file):\n",
    "            if str(file).endswith(str(epochs-1) + '.tar'): \n",
    "                return os.path.join(basepath, file)\n",
    "            \n",
    "    print(\"COULDNT FIND MODEL\")\n",
    "    assert True==False # just throw an error. \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def load_model(cv_fold, loss_type): \n",
    "    \n",
    "    print(\"HELLO\")\n",
    "    model = models.__dict__[args.arch]()\n",
    "    # CIFAR 10 model\n",
    "    \n",
    "    if args.dataid ==\"cifar10\":\n",
    "    # use the layer the SIMCLR authors used for cifar10 input conv, checked all padding/strides too.\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1,1), padding=(1,1), bias=False)\n",
    "        model.maxpool = nn.Identity()\n",
    "\n",
    "    # freeze all layers but the last fc\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            param.requires_grad = False\n",
    "    # init the fc layer\n",
    "    if args.dataid == \"cifar10\":\n",
    "\n",
    "        if loss_type == 'supervised':\n",
    "            model.fc = torch.nn.Linear(model.fc.in_features, 10) # note this is for cifar 10.\n",
    "        elif loss_type =='rotation': \n",
    "            model.fc = torch.nn.Linear(model.fc.in_features, 4)\n",
    "\n",
    "\n",
    "    if loss_type == 'supervised': \n",
    "        savefile = os.path.join(args.checkpoint_fp, \n",
    "                                \"{}_lincls_best.tar\".format(args.checkpoints[cv_fold]))\n",
    "    elif loss_type == 'rotation': \n",
    "        savefile = os.path.join(args.checkpoint_fp, \n",
    "                                 \"{}_lincls_best_rotation.tar\".format(args.checkpoints[cv_fold]))\n",
    "\n",
    "    elif loss_type == 'icl' or loss_type == 'icl_and_rotation': \n",
    "#         print('ICL')\n",
    "        heads = {}\n",
    "        if not args.nomoco:\n",
    "            heads[\"moco\"] = {\n",
    "            \"num_classes\": args.moco_dim\n",
    "        }\n",
    "        \n",
    "#         print(heads)\n",
    "\n",
    "        model = moco.builder.MoCo(\n",
    "            models.__dict__[args.arch],\n",
    "            K=args.moco_k, m=args.moco_m, T=args.moco_t, mlp=args.mlp, dataid=args.dataid,\n",
    "            multitask_heads=heads\n",
    "        )\n",
    "        savefile = find_model(args.checkpoints[cv_fold], cv_fold)\n",
    "        \n",
    "#     print('savefile', savefile)\n",
    "    ckpt = torch.load(savefile, map_location=\"cpu\")\n",
    "    \n",
    "    state_dict = ckpt['state_dict']\n",
    "    \n",
    "    for k in list(state_dict.keys()):\n",
    "        # retain only encoder_q up to before the embedding layer\n",
    "        if k.startswith('module'):\n",
    "            state_dict[k[len(\"module.\"):]] = state_dict[k] \n",
    "            del state_dict[k]\n",
    "\n",
    "                \n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "m = load_model(0, args.loss)    \n",
    "\n",
    "def rotate_images(images):\n",
    "    nimages = images.shape[0]\n",
    "    n_rot_images = 4*nimages\n",
    "\n",
    "    # rotate images all 4 ways at once\n",
    "    rotated_images = torch.zeros([n_rot_images, images.shape[1], images.shape[2], images.shape[3]]).cuda()\n",
    "    rot_classes = torch.zeros([n_rot_images]).long().cuda()\n",
    "\n",
    "    rotated_images[:nimages] = images\n",
    "    # rotate 90\n",
    "    rotated_images[nimages:2*nimages] = images.flip(3).transpose(2,3)\n",
    "    rot_classes[nimages:2*nimages] = 1\n",
    "    # rotate 180\n",
    "    rotated_images[2*nimages:3*nimages] = images.flip(3).flip(2)\n",
    "    rot_classes[2*nimages:3*nimages] = 2\n",
    "    # rotate 270\n",
    "    rotated_images[3*nimages:4*nimages] = images.transpose(2,3).flip(3)\n",
    "    rot_classes[3*nimages:4*nimages] = 3\n",
    "\n",
    "    return rotated_images, rot_classes\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "def eval_augmentations(config): \n",
    "    augment = config\n",
    "    print('called', augment)\n",
    "    \n",
    "    if args.loss == 'icl_and_rotation':\n",
    "        \n",
    "        losses = ['icl', 'rotation']\n",
    "        \n",
    "    else: \n",
    "        losses = [args.loss]\n",
    "        \n",
    "    \n",
    "    metrics = Accumulator()\n",
    "    \n",
    "    for loss_type in losses: \n",
    "        # TODO MOve this out\n",
    "#         metrics = Accumulator()\n",
    "      \n",
    "        print(loss_type)\n",
    "        \n",
    "        augmentations = policy_decoder(augment, augment['num_policy'], augment['num_op'])\n",
    "        \n",
    "        \n",
    "        fold = augment['cv_fold']\n",
    "        model = load_model(cv_fold, loss_type).cuda()\n",
    "        model.eval()\n",
    "        loaders = []\n",
    "\n",
    "        for _ in range(args.num_policy): #TODO: \n",
    "            _, validloader = get_dataloaders(augmentations, 512, kfold=fold, loss_type=loss_type)\n",
    "            loaders.append(iter(validloader))\n",
    "            del _\n",
    "\n",
    "     \n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        try: \n",
    "\n",
    "            i = 0\n",
    "            with torch.no_grad(): \n",
    "                while True: \n",
    "                    losses = []\n",
    "                    corrects = []\n",
    "\n",
    "                    for loader in loaders:\n",
    "\n",
    "                        if not loss_type == 'icl':\n",
    "\n",
    "                            data, label = next(loader)\n",
    "                            data = data.cuda()\n",
    "                            label = label.cuda()\n",
    "\n",
    "                            if loss_type == 'supervised':\n",
    "                                pred = model(data)\n",
    "\n",
    "                            if loss_type ==\"rotation\":\n",
    "                                rotated_images, label = rotate_images(data)\n",
    "                                pred = model(rotated_images)  \n",
    "\n",
    "                        else: \n",
    "\n",
    "                            images, _ = next(loader)\n",
    "                            images[0] = images[0].cuda(non_blocking=True)\n",
    "                            images[1] = images[1].cuda(non_blocking=True)\n",
    "                            pred, label =model(head=\"moco\", im_q=images[0], im_k=images[1], evaluate=True)\n",
    "                            acc = accuracy(pred, label)\n",
    "\n",
    "                        loss = loss_fn(pred, label)\n",
    "                        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                        _, pred = pred.topk(1, 1, True, True)\n",
    "                        pred = pred.t()\n",
    "                        correct = pred.eq(label.view(1, -1).expand_as(pred)).detach().cpu().numpy()\n",
    "                        corrects.append(correct)\n",
    "\n",
    "                        if not loss_type == 'icl':\n",
    "                            del loss, correct, pred, data, label\n",
    "                        else: \n",
    "                            del loss, images, pred, label, correct\n",
    "\n",
    "\n",
    "\n",
    "                    losses = np.concatenate(losses)\n",
    "#                     print('losses shape' , losses.shape)\n",
    "                    losses_min = np.mean(losses) # get it so it averages out.\n",
    "                    corrects = np.concatenate(corrects)\n",
    "                    corrects_max = np.max(corrects, axis=0).squeeze()\n",
    "#                     print('len corrects max', len(corrects_max), 'corrects shape', corrects.shape)\n",
    "                    \n",
    "                    print('l shape', losses.shape)\n",
    "                    print('corrects shape', corrects.shape)\n",
    "                    print('len c max', len(corrects_max))\n",
    "                    losses_min *= losses.shape[0]/5\n",
    "                    \n",
    "                    if loss_type == 'rotation': \n",
    "                        metrics.add_dict({ \n",
    "                            'minus_loss': -.25*np.sum(losses_min)*args.loss_weights[loss_type],\n",
    "                            'plus_loss': np.sum(losses_min)*args.loss_weights[loss_type],\n",
    "                            'correct': np.sum(corrects_max)*args.loss_weights[loss_type],\n",
    "                            'cnt': len(corrects_max)})\n",
    "                        del corrects, corrects_max\n",
    "                    else: \n",
    "                        metrics.add_dict({ \n",
    "                            'minus_loss': -1*np.sum(losses_min)*args.loss_weights[loss_type],\n",
    "                            'plus_loss': np.sum(losses_min)*args.loss_weights[loss_type],\n",
    "                            'correct': np.sum(corrects_max)*args.loss_weights[loss_type],\n",
    "                            'cnt': len(corrects_max)})\n",
    "                        del corrects, corrects_max\n",
    "\n",
    "                    print('correct', metrics['correct']/metrics['cnt'])\n",
    "        except StopIteration: \n",
    "            pass\n",
    "    \n",
    "    del model\n",
    "    metrics = metrics/'cnt'\n",
    "    tune.track.log(top_1_valid=metrics['correct'], minus_loss=metrics['minus_loss'], plus_loss=metrics['plus_loss'])\n",
    "    print(metrics['correct'])\n",
    "    return metrics['minus_loss']\n",
    "\n",
    "ops = augment_list(False) # Get the default augmentation set. \n",
    "# Define the space of our augmentations. \n",
    "space = {}\n",
    "for i in range(args.num_policy): \n",
    "    for j in range(args.num_op):\n",
    "        space['policy_%d_%d' %(i,j)]  = hp.choice('policy_%d_%d' %(i, j), list(range(0, len(ops))))\n",
    "        space['prob_%d_%d' %(i, j)] = hp.uniform('prob_%d_%d' %(i, j), 0.0, 1.0)\n",
    "        space['level_%d_%d' %(i, j)] = hp.uniform('level_%d_%d' %(i, j), 0.0, 1.0)\n",
    "\n",
    "final_policy_set = []\n",
    "\n",
    "if not args.loss == 'icl': \n",
    "    reward_attr = 'minus_loss'\n",
    "else: \n",
    "    reward_attr = 'minus_loss'\n",
    "    \n",
    "    \n",
    "# TODO: let this be whatever we want. \n",
    "object_store_memory = int(0.6 * ray.utils.get_system_memory() // 10 ** 9 * 10 ** 9)\n",
    "\n",
    "# TODO Change back\n",
    "ray.init(num_gpus=2, ignore_reinit_error=True, \n",
    "    num_cpus=28\n",
    "    )\n",
    "# ray.init(num_gpus=1, memory=200*1024*1024*100, object_store_memory=200*1024*1024*50)\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "cv_num = 5\n",
    "num_result_per_cv = 10\n",
    "\n",
    "for _ in range(2): \n",
    "    for cv_fold in range(cv_num): \n",
    "        name = \"slm_moco_min_debug_ICL_rot_search_%s_fold_%d\" %(args.dataid, cv_fold)\n",
    "        hyperopt_search=HyperOptSearch(space, \n",
    "            max_concurrent=1,\n",
    "            metric=reward_attr,\n",
    "            mode='max')\n",
    "\n",
    "\n",
    "        results = tune.run(\n",
    "            eval_augmentations,\n",
    "            name=name,\n",
    "            num_samples=200,\n",
    "            resources_per_trial={\n",
    "                \"gpu\": 1\n",
    "            },\n",
    "            search_alg=hyperopt_search,\n",
    "            verbose=2,\n",
    "            config = { \n",
    "                'num_op': args.num_op, \n",
    "                'num_policy': args.num_policy, \n",
    "                'cv_fold': cv_fold\n",
    "            },\n",
    "            return_trials=True,\n",
    "            stop={'training_iteration': 1},\n",
    "        )\n",
    "        results_copy = results\n",
    "        results = [x for x in results if x.last_result is not None]\n",
    "        results = sorted(results, key= lambda x: x.last_result[reward_attr], reverse=True)\n",
    "\n",
    "        for result in results[:num_result_per_cv]: \n",
    "            final_policy = policy_decoder(result.config, args.num_policy, args.num_op)\n",
    "            final_policy_set.extend(final_policy)\n",
    "\n",
    "        print(final_policy)\n",
    "print(final_policy_set)\n",
    "\n",
    "# Start saving to a path called policies. \n",
    "import pickle\n",
    "savefp = os.path.join(args.policy_dir, str(args.base+'_'+args.loss+ '_' + (str(reward_attr) + '.pkl')))\n",
    "with open(savefp, 'wb') as f: \n",
    "    pickle.dump(final_policy_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
