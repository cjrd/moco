{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moco.moco'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-799651042c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/userdata/smetzger/all_deepul_files/deepul_proj/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moco.moco'"
     ]
    }
   ],
   "source": [
    "# CODE is based of fastautoagument code here \n",
    "\n",
    "# https://github.com/kakaobrain/fast-autoaugment/blob/master/FastAutoAugment/search.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import ray \n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import track\n",
    "\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "from ray.tune import register_trainable, run_experiments\n",
    "import wandb\n",
    "import argparse\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"/userdata/smetzger/all_deepul_files/deepul_proj/\")\n",
    "\n",
    "import moco.loader\n",
    "import moco.builder\n",
    "\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "import os\n",
    "import ray.tune as tune\n",
    "\n",
    "\n",
    "\n",
    "# FOR DEBUG\n",
    "class Args:\n",
    "    checkpoints = ['fxrZE', 'lJu2W', 'rdEIg', 'esdq2' ,'vnhKs'] # Ordered KFOLDS order. Make this nicer.\n",
    "    checkpoint_fp = '/userdata/smetzger/all_deepul_files/ckpts'\n",
    "    data = '/userdata/smetzger/data/cifar_10/'\n",
    "    \n",
    "    # Some args for the Fast Autoaugment thing. \n",
    "    num_op = 2\n",
    "    num_policy=5\n",
    "    num_search = 200\n",
    "    dataid = 'cifar10'\n",
    "    cv_ratio=1.0\n",
    "    smoke_test=False\n",
    "    resume=False\n",
    "    arch = 'resnet50'\n",
    "    distributed=False\n",
    "    loss = 'icl'# one of rotation, supervised, icl, icl_and_rotation.\n",
    "    \n",
    "    # Moco args. \n",
    "    moco_k = 65536\n",
    "    moco_m = 0.999\n",
    "    moco_t = 0.2\n",
    "    \n",
    "    \n",
    "    # Whether or not to use the MLP for mocov2\n",
    "    mlp = True\n",
    "    \n",
    "    # Model input args for building the model head. \n",
    "    nomoco = False\n",
    "    rotnet = False\n",
    "    \n",
    "    moco_dim = 128\n",
    "    \n",
    "    \n",
    "args=Args()\n",
    "print('args', args)\n",
    "\n",
    "import random\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.transforms import Compose\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "random_mirror = True\n",
    "from autoaug_scripts import augment_list, Augmentation, Accumulator\n",
    "\n",
    "# Define how we load our dataloaders. \n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'moco' from '/userdata/smetzger/all_deepul_files/deepul_proj/moco/moco/__init__.py'>\n",
      "<module 'moco' from '/userdata/smetzger/all_deepul_files/deepul_proj/moco/moco/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(moco)\n",
    "import moco\n",
    "print(moco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(augmentations, batch=1024, kfold=0, get_train=False):\n",
    "\n",
    "    \"\"\"\n",
    "    input: augmentations: the list of the augmentations you want applied to the data. \n",
    "    batch = batchsize, \n",
    "    kfold, which fold you want to look at (0, 1,2 3, or 4)\n",
    "    get_train, whether or not you want the train data. Use this when loading the data to train linear classifiers, \n",
    "    slash when you're loading the final classifier. \n",
    "    \"\"\"\n",
    "    if args.dataid == \"imagenet\":\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            traindir,\n",
    "            transformations)\n",
    "\n",
    "        # TODO: add imagenet transforms etc. \n",
    "    elif args.dataid == \"cifar10\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "        \n",
    "        if args.loss == \"icl\": \n",
    "            transform_train = transforms.Compose([\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "            transforms.RandomHorizontalFlip(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "                \n",
    "            ])\n",
    "\n",
    "        transform_train.transforms.insert(0, Augmentation(augmentations))\n",
    "        transform_train = moco.loader.TwoCropsTransform\n",
    "        \n",
    "        \n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Support for the following dataset is not yet implemented: {}\".format(args.dataid))\n",
    "\n",
    "    if get_train: \n",
    "        train_dataset = torchvision.datasets.CIFAR10(args.data,\n",
    "                                                     transform=transform_train,\n",
    "                                                     download=True)\n",
    "\n",
    "    # NOTE THAT IN THE FAA PAPER THE USED TRANSFORM TRAIN.     \n",
    "    val_dataset = torchvision.datasets.CIFAR10(args.data, transform=transform_train, \n",
    "        download=True)\n",
    "\n",
    "    if get_train: \n",
    "        torch.manual_seed(1337)\n",
    "        lengths = [len(train_dataset)//5]*5\n",
    "        folds = torch.utils.data.random_split(train_dataset, lengths)\n",
    "        folds.pop(kfold)\n",
    "        train_dataset = torch.utils.data.ConcatDataset(folds)\n",
    "\n",
    "\n",
    "    torch.manual_seed(1337)\n",
    "    lengths = [len(val_dataset)//5]*5\n",
    "    folds = torch.utils.data.random_split(val_dataset, lengths)\n",
    "    val_dataset = folds[kfold]\n",
    "\n",
    "    if get_train: \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch, shuffle=(train_sampler is None),\n",
    "            num_workers=8, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    val_loader= torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch, shuffle=False,\n",
    "        num_workers=4, pin_memory=True, drop_last=False\n",
    "    )\n",
    "\n",
    "    if not get_train: \n",
    "        train_loader = None\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savefile /userdata/smetzger/all_deepul_files/ckpts/fxrZE_resnet50_750epochs_512bsz_0.4000lr_0.9000mtm_120-160sched_128.0000mocod_65536mocok_0.9990mocom_0.2000mocot_1.000e-04wd_mlp_augplus_cos_fold_0_0749.tar\n",
      "module.queue\n",
      "module.queue_ptr\n",
      "module.model.encoder.conv1.weight\n",
      "module.model.encoder.bn1.weight\n",
      "module.model.encoder.bn1.bias\n",
      "module.model.encoder.bn1.running_mean\n",
      "module.model.encoder.bn1.running_var\n",
      "module.model.encoder.bn1.num_batches_tracked\n",
      "module.model.encoder.layer1.0.conv1.weight\n",
      "module.model.encoder.layer1.0.bn1.weight\n",
      "module.model.encoder.layer1.0.bn1.bias\n",
      "module.model.encoder.layer1.0.bn1.running_mean\n",
      "module.model.encoder.layer1.0.bn1.running_var\n",
      "module.model.encoder.layer1.0.bn1.num_batches_tracked\n",
      "module.model.encoder.layer1.0.conv2.weight\n",
      "module.model.encoder.layer1.0.bn2.weight\n",
      "module.model.encoder.layer1.0.bn2.bias\n",
      "module.model.encoder.layer1.0.bn2.running_mean\n",
      "module.model.encoder.layer1.0.bn2.running_var\n",
      "module.model.encoder.layer1.0.bn2.num_batches_tracked\n",
      "module.model.encoder.layer1.0.conv3.weight\n",
      "module.model.encoder.layer1.0.bn3.weight\n",
      "module.model.encoder.layer1.0.bn3.bias\n",
      "module.model.encoder.layer1.0.bn3.running_mean\n",
      "module.model.encoder.layer1.0.bn3.running_var\n",
      "module.model.encoder.layer1.0.bn3.num_batches_tracked\n",
      "module.model.encoder.layer1.0.downsample.0.weight\n",
      "module.model.encoder.layer1.0.downsample.1.weight\n",
      "module.model.encoder.layer1.0.downsample.1.bias\n",
      "module.model.encoder.layer1.0.downsample.1.running_mean\n",
      "module.model.encoder.layer1.0.downsample.1.running_var\n",
      "module.model.encoder.layer1.0.downsample.1.num_batches_tracked\n",
      "module.model.encoder.layer1.1.conv1.weight\n",
      "module.model.encoder.layer1.1.bn1.weight\n",
      "module.model.encoder.layer1.1.bn1.bias\n",
      "module.model.encoder.layer1.1.bn1.running_mean\n",
      "module.model.encoder.layer1.1.bn1.running_var\n",
      "module.model.encoder.layer1.1.bn1.num_batches_tracked\n",
      "module.model.encoder.layer1.1.conv2.weight\n",
      "module.model.encoder.layer1.1.bn2.weight\n",
      "module.model.encoder.layer1.1.bn2.bias\n",
      "module.model.encoder.layer1.1.bn2.running_mean\n",
      "module.model.encoder.layer1.1.bn2.running_var\n",
      "module.model.encoder.layer1.1.bn2.num_batches_tracked\n",
      "module.model.encoder.layer1.1.conv3.weight\n",
      "module.model.encoder.layer1.1.bn3.weight\n",
      "module.model.encoder.layer1.1.bn3.bias\n",
      "module.model.encoder.layer1.1.bn3.running_mean\n",
      "module.model.encoder.layer1.1.bn3.running_var\n",
      "module.model.encoder.layer1.1.bn3.num_batches_tracked\n",
      "module.model.encoder.layer1.2.conv1.weight\n",
      "module.model.encoder.layer1.2.bn1.weight\n",
      "module.model.encoder.layer1.2.bn1.bias\n",
      "module.model.encoder.layer1.2.bn1.running_mean\n",
      "module.model.encoder.layer1.2.bn1.running_var\n",
      "module.model.encoder.layer1.2.bn1.num_batches_tracked\n",
      "module.model.encoder.layer1.2.conv2.weight\n",
      "module.model.encoder.layer1.2.bn2.weight\n",
      "module.model.encoder.layer1.2.bn2.bias\n",
      "module.model.encoder.layer1.2.bn2.running_mean\n",
      "module.model.encoder.layer1.2.bn2.running_var\n",
      "module.model.encoder.layer1.2.bn2.num_batches_tracked\n",
      "module.model.encoder.layer1.2.conv3.weight\n",
      "module.model.encoder.layer1.2.bn3.weight\n",
      "module.model.encoder.layer1.2.bn3.bias\n",
      "module.model.encoder.layer1.2.bn3.running_mean\n",
      "module.model.encoder.layer1.2.bn3.running_var\n",
      "module.model.encoder.layer1.2.bn3.num_batches_tracked\n",
      "module.model.encoder.layer2.0.conv1.weight\n",
      "module.model.encoder.layer2.0.bn1.weight\n",
      "module.model.encoder.layer2.0.bn1.bias\n",
      "module.model.encoder.layer2.0.bn1.running_mean\n",
      "module.model.encoder.layer2.0.bn1.running_var\n",
      "module.model.encoder.layer2.0.bn1.num_batches_tracked\n",
      "module.model.encoder.layer2.0.conv2.weight\n",
      "module.model.encoder.layer2.0.bn2.weight\n",
      "module.model.encoder.layer2.0.bn2.bias\n",
      "module.model.encoder.layer2.0.bn2.running_mean\n",
      "module.model.encoder.layer2.0.bn2.running_var\n",
      "module.model.encoder.layer2.0.bn2.num_batches_tracked\n",
      "module.model.encoder.layer2.0.conv3.weight\n",
      "module.model.encoder.layer2.0.bn3.weight\n",
      "module.model.encoder.layer2.0.bn3.bias\n",
      "module.model.encoder.layer2.0.bn3.running_mean\n",
      "module.model.encoder.layer2.0.bn3.running_var\n",
      "module.model.encoder.layer2.0.bn3.num_batches_tracked\n",
      "module.model.encoder.layer2.0.downsample.0.weight\n",
      "module.model.encoder.layer2.0.downsample.1.weight\n",
      "module.model.encoder.layer2.0.downsample.1.bias\n",
      "module.model.encoder.layer2.0.downsample.1.running_mean\n",
      "module.model.encoder.layer2.0.downsample.1.running_var\n",
      "module.model.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "module.model.encoder.layer2.1.conv1.weight\n",
      "module.model.encoder.layer2.1.bn1.weight\n",
      "module.model.encoder.layer2.1.bn1.bias\n",
      "module.model.encoder.layer2.1.bn1.running_mean\n",
      "module.model.encoder.layer2.1.bn1.running_var\n",
      "module.model.encoder.layer2.1.bn1.num_batches_tracked\n",
      "module.model.encoder.layer2.1.conv2.weight\n",
      "module.model.encoder.layer2.1.bn2.weight\n",
      "module.model.encoder.layer2.1.bn2.bias\n",
      "module.model.encoder.layer2.1.bn2.running_mean\n",
      "module.model.encoder.layer2.1.bn2.running_var\n",
      "module.model.encoder.layer2.1.bn2.num_batches_tracked\n",
      "module.model.encoder.layer2.1.conv3.weight\n",
      "module.model.encoder.layer2.1.bn3.weight\n",
      "module.model.encoder.layer2.1.bn3.bias\n",
      "module.model.encoder.layer2.1.bn3.running_mean\n",
      "module.model.encoder.layer2.1.bn3.running_var\n",
      "module.model.encoder.layer2.1.bn3.num_batches_tracked\n",
      "module.model.encoder.layer2.2.conv1.weight\n",
      "module.model.encoder.layer2.2.bn1.weight\n",
      "module.model.encoder.layer2.2.bn1.bias\n",
      "module.model.encoder.layer2.2.bn1.running_mean\n",
      "module.model.encoder.layer2.2.bn1.running_var\n",
      "module.model.encoder.layer2.2.bn1.num_batches_tracked\n",
      "module.model.encoder.layer2.2.conv2.weight\n",
      "module.model.encoder.layer2.2.bn2.weight\n",
      "module.model.encoder.layer2.2.bn2.bias\n",
      "module.model.encoder.layer2.2.bn2.running_mean\n",
      "module.model.encoder.layer2.2.bn2.running_var\n",
      "module.model.encoder.layer2.2.bn2.num_batches_tracked\n",
      "module.model.encoder.layer2.2.conv3.weight\n",
      "module.model.encoder.layer2.2.bn3.weight\n",
      "module.model.encoder.layer2.2.bn3.bias\n",
      "module.model.encoder.layer2.2.bn3.running_mean\n",
      "module.model.encoder.layer2.2.bn3.running_var\n",
      "module.model.encoder.layer2.2.bn3.num_batches_tracked\n",
      "module.model.encoder.layer2.3.conv1.weight\n",
      "module.model.encoder.layer2.3.bn1.weight\n",
      "module.model.encoder.layer2.3.bn1.bias\n",
      "module.model.encoder.layer2.3.bn1.running_mean\n",
      "module.model.encoder.layer2.3.bn1.running_var\n",
      "module.model.encoder.layer2.3.bn1.num_batches_tracked\n",
      "module.model.encoder.layer2.3.conv2.weight\n",
      "module.model.encoder.layer2.3.bn2.weight\n",
      "module.model.encoder.layer2.3.bn2.bias\n",
      "module.model.encoder.layer2.3.bn2.running_mean\n",
      "module.model.encoder.layer2.3.bn2.running_var\n",
      "module.model.encoder.layer2.3.bn2.num_batches_tracked\n",
      "module.model.encoder.layer2.3.conv3.weight\n",
      "module.model.encoder.layer2.3.bn3.weight\n",
      "module.model.encoder.layer2.3.bn3.bias\n",
      "module.model.encoder.layer2.3.bn3.running_mean\n",
      "module.model.encoder.layer2.3.bn3.running_var\n",
      "module.model.encoder.layer2.3.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.0.conv1.weight\n",
      "module.model.encoder.layer3.0.bn1.weight\n",
      "module.model.encoder.layer3.0.bn1.bias\n",
      "module.model.encoder.layer3.0.bn1.running_mean\n",
      "module.model.encoder.layer3.0.bn1.running_var\n",
      "module.model.encoder.layer3.0.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.0.conv2.weight\n",
      "module.model.encoder.layer3.0.bn2.weight\n",
      "module.model.encoder.layer3.0.bn2.bias\n",
      "module.model.encoder.layer3.0.bn2.running_mean\n",
      "module.model.encoder.layer3.0.bn2.running_var\n",
      "module.model.encoder.layer3.0.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.0.conv3.weight\n",
      "module.model.encoder.layer3.0.bn3.weight\n",
      "module.model.encoder.layer3.0.bn3.bias\n",
      "module.model.encoder.layer3.0.bn3.running_mean\n",
      "module.model.encoder.layer3.0.bn3.running_var\n",
      "module.model.encoder.layer3.0.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.0.downsample.0.weight\n",
      "module.model.encoder.layer3.0.downsample.1.weight\n",
      "module.model.encoder.layer3.0.downsample.1.bias\n",
      "module.model.encoder.layer3.0.downsample.1.running_mean\n",
      "module.model.encoder.layer3.0.downsample.1.running_var\n",
      "module.model.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "module.model.encoder.layer3.1.conv1.weight\n",
      "module.model.encoder.layer3.1.bn1.weight\n",
      "module.model.encoder.layer3.1.bn1.bias\n",
      "module.model.encoder.layer3.1.bn1.running_mean\n",
      "module.model.encoder.layer3.1.bn1.running_var\n",
      "module.model.encoder.layer3.1.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.1.conv2.weight\n",
      "module.model.encoder.layer3.1.bn2.weight\n",
      "module.model.encoder.layer3.1.bn2.bias\n",
      "module.model.encoder.layer3.1.bn2.running_mean\n",
      "module.model.encoder.layer3.1.bn2.running_var\n",
      "module.model.encoder.layer3.1.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.1.conv3.weight\n",
      "module.model.encoder.layer3.1.bn3.weight\n",
      "module.model.encoder.layer3.1.bn3.bias\n",
      "module.model.encoder.layer3.1.bn3.running_mean\n",
      "module.model.encoder.layer3.1.bn3.running_var\n",
      "module.model.encoder.layer3.1.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.2.conv1.weight\n",
      "module.model.encoder.layer3.2.bn1.weight\n",
      "module.model.encoder.layer3.2.bn1.bias\n",
      "module.model.encoder.layer3.2.bn1.running_mean\n",
      "module.model.encoder.layer3.2.bn1.running_var\n",
      "module.model.encoder.layer3.2.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.2.conv2.weight\n",
      "module.model.encoder.layer3.2.bn2.weight\n",
      "module.model.encoder.layer3.2.bn2.bias\n",
      "module.model.encoder.layer3.2.bn2.running_mean\n",
      "module.model.encoder.layer3.2.bn2.running_var\n",
      "module.model.encoder.layer3.2.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.2.conv3.weight\n",
      "module.model.encoder.layer3.2.bn3.weight\n",
      "module.model.encoder.layer3.2.bn3.bias\n",
      "module.model.encoder.layer3.2.bn3.running_mean\n",
      "module.model.encoder.layer3.2.bn3.running_var\n",
      "module.model.encoder.layer3.2.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.3.conv1.weight\n",
      "module.model.encoder.layer3.3.bn1.weight\n",
      "module.model.encoder.layer3.3.bn1.bias\n",
      "module.model.encoder.layer3.3.bn1.running_mean\n",
      "module.model.encoder.layer3.3.bn1.running_var\n",
      "module.model.encoder.layer3.3.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.3.conv2.weight\n",
      "module.model.encoder.layer3.3.bn2.weight\n",
      "module.model.encoder.layer3.3.bn2.bias\n",
      "module.model.encoder.layer3.3.bn2.running_mean\n",
      "module.model.encoder.layer3.3.bn2.running_var\n",
      "module.model.encoder.layer3.3.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.3.conv3.weight\n",
      "module.model.encoder.layer3.3.bn3.weight\n",
      "module.model.encoder.layer3.3.bn3.bias\n",
      "module.model.encoder.layer3.3.bn3.running_mean\n",
      "module.model.encoder.layer3.3.bn3.running_var\n",
      "module.model.encoder.layer3.3.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.4.conv1.weight\n",
      "module.model.encoder.layer3.4.bn1.weight\n",
      "module.model.encoder.layer3.4.bn1.bias\n",
      "module.model.encoder.layer3.4.bn1.running_mean\n",
      "module.model.encoder.layer3.4.bn1.running_var\n",
      "module.model.encoder.layer3.4.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.4.conv2.weight\n",
      "module.model.encoder.layer3.4.bn2.weight\n",
      "module.model.encoder.layer3.4.bn2.bias\n",
      "module.model.encoder.layer3.4.bn2.running_mean\n",
      "module.model.encoder.layer3.4.bn2.running_var\n",
      "module.model.encoder.layer3.4.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.4.conv3.weight\n",
      "module.model.encoder.layer3.4.bn3.weight\n",
      "module.model.encoder.layer3.4.bn3.bias\n",
      "module.model.encoder.layer3.4.bn3.running_mean\n",
      "module.model.encoder.layer3.4.bn3.running_var\n",
      "module.model.encoder.layer3.4.bn3.num_batches_tracked\n",
      "module.model.encoder.layer3.5.conv1.weight\n",
      "module.model.encoder.layer3.5.bn1.weight\n",
      "module.model.encoder.layer3.5.bn1.bias\n",
      "module.model.encoder.layer3.5.bn1.running_mean\n",
      "module.model.encoder.layer3.5.bn1.running_var\n",
      "module.model.encoder.layer3.5.bn1.num_batches_tracked\n",
      "module.model.encoder.layer3.5.conv2.weight\n",
      "module.model.encoder.layer3.5.bn2.weight\n",
      "module.model.encoder.layer3.5.bn2.bias\n",
      "module.model.encoder.layer3.5.bn2.running_mean\n",
      "module.model.encoder.layer3.5.bn2.running_var\n",
      "module.model.encoder.layer3.5.bn2.num_batches_tracked\n",
      "module.model.encoder.layer3.5.conv3.weight\n",
      "module.model.encoder.layer3.5.bn3.weight\n",
      "module.model.encoder.layer3.5.bn3.bias\n",
      "module.model.encoder.layer3.5.bn3.running_mean\n",
      "module.model.encoder.layer3.5.bn3.running_var\n",
      "module.model.encoder.layer3.5.bn3.num_batches_tracked\n",
      "module.model.encoder.layer4.0.conv1.weight\n",
      "module.model.encoder.layer4.0.bn1.weight\n",
      "module.model.encoder.layer4.0.bn1.bias\n",
      "module.model.encoder.layer4.0.bn1.running_mean\n",
      "module.model.encoder.layer4.0.bn1.running_var\n",
      "module.model.encoder.layer4.0.bn1.num_batches_tracked\n",
      "module.model.encoder.layer4.0.conv2.weight\n",
      "module.model.encoder.layer4.0.bn2.weight\n",
      "module.model.encoder.layer4.0.bn2.bias\n",
      "module.model.encoder.layer4.0.bn2.running_mean\n",
      "module.model.encoder.layer4.0.bn2.running_var\n",
      "module.model.encoder.layer4.0.bn2.num_batches_tracked\n",
      "module.model.encoder.layer4.0.conv3.weight\n",
      "module.model.encoder.layer4.0.bn3.weight\n",
      "module.model.encoder.layer4.0.bn3.bias\n",
      "module.model.encoder.layer4.0.bn3.running_mean\n",
      "module.model.encoder.layer4.0.bn3.running_var\n",
      "module.model.encoder.layer4.0.bn3.num_batches_tracked\n",
      "module.model.encoder.layer4.0.downsample.0.weight\n",
      "module.model.encoder.layer4.0.downsample.1.weight\n",
      "module.model.encoder.layer4.0.downsample.1.bias\n",
      "module.model.encoder.layer4.0.downsample.1.running_mean\n",
      "module.model.encoder.layer4.0.downsample.1.running_var\n",
      "module.model.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "module.model.encoder.layer4.1.conv1.weight\n",
      "module.model.encoder.layer4.1.bn1.weight\n",
      "module.model.encoder.layer4.1.bn1.bias\n",
      "module.model.encoder.layer4.1.bn1.running_mean\n",
      "module.model.encoder.layer4.1.bn1.running_var\n",
      "module.model.encoder.layer4.1.bn1.num_batches_tracked\n",
      "module.model.encoder.layer4.1.conv2.weight\n",
      "module.model.encoder.layer4.1.bn2.weight\n",
      "module.model.encoder.layer4.1.bn2.bias\n",
      "module.model.encoder.layer4.1.bn2.running_mean\n",
      "module.model.encoder.layer4.1.bn2.running_var\n",
      "module.model.encoder.layer4.1.bn2.num_batches_tracked\n",
      "module.model.encoder.layer4.1.conv3.weight\n",
      "module.model.encoder.layer4.1.bn3.weight\n",
      "module.model.encoder.layer4.1.bn3.bias\n",
      "module.model.encoder.layer4.1.bn3.running_mean\n",
      "module.model.encoder.layer4.1.bn3.running_var\n",
      "module.model.encoder.layer4.1.bn3.num_batches_tracked\n",
      "module.model.encoder.layer4.2.conv1.weight\n",
      "module.model.encoder.layer4.2.bn1.weight\n",
      "module.model.encoder.layer4.2.bn1.bias\n",
      "module.model.encoder.layer4.2.bn1.running_mean\n",
      "module.model.encoder.layer4.2.bn1.running_var\n",
      "module.model.encoder.layer4.2.bn1.num_batches_tracked\n",
      "module.model.encoder.layer4.2.conv2.weight\n",
      "module.model.encoder.layer4.2.bn2.weight\n",
      "module.model.encoder.layer4.2.bn2.bias\n",
      "module.model.encoder.layer4.2.bn2.running_mean\n",
      "module.model.encoder.layer4.2.bn2.running_var\n",
      "module.model.encoder.layer4.2.bn2.num_batches_tracked\n",
      "module.model.encoder.layer4.2.conv3.weight\n",
      "module.model.encoder.layer4.2.bn3.weight\n",
      "module.model.encoder.layer4.2.bn3.bias\n",
      "module.model.encoder.layer4.2.bn3.running_mean\n",
      "module.model.encoder.layer4.2.bn3.running_var\n",
      "module.model.encoder.layer4.2.bn3.num_batches_tracked\n",
      "module.model.moco.0.weight\n",
      "module.model.moco.0.bias\n",
      "module.model.moco.2.weight\n",
      "module.model.moco.2.bias\n",
      "module.encoder_k.conv1.weight\n",
      "module.encoder_k.bn1.weight\n",
      "module.encoder_k.bn1.bias\n",
      "module.encoder_k.bn1.running_mean\n",
      "module.encoder_k.bn1.running_var\n",
      "module.encoder_k.bn1.num_batches_tracked\n",
      "module.encoder_k.layer1.0.conv1.weight\n",
      "module.encoder_k.layer1.0.bn1.weight\n",
      "module.encoder_k.layer1.0.bn1.bias\n",
      "module.encoder_k.layer1.0.bn1.running_mean\n",
      "module.encoder_k.layer1.0.bn1.running_var\n",
      "module.encoder_k.layer1.0.bn1.num_batches_tracked\n",
      "module.encoder_k.layer1.0.conv2.weight\n",
      "module.encoder_k.layer1.0.bn2.weight\n",
      "module.encoder_k.layer1.0.bn2.bias\n",
      "module.encoder_k.layer1.0.bn2.running_mean\n",
      "module.encoder_k.layer1.0.bn2.running_var\n",
      "module.encoder_k.layer1.0.bn2.num_batches_tracked\n",
      "module.encoder_k.layer1.0.conv3.weight\n",
      "module.encoder_k.layer1.0.bn3.weight\n",
      "module.encoder_k.layer1.0.bn3.bias\n",
      "module.encoder_k.layer1.0.bn3.running_mean\n",
      "module.encoder_k.layer1.0.bn3.running_var\n",
      "module.encoder_k.layer1.0.bn3.num_batches_tracked\n",
      "module.encoder_k.layer1.0.downsample.0.weight\n",
      "module.encoder_k.layer1.0.downsample.1.weight\n",
      "module.encoder_k.layer1.0.downsample.1.bias\n",
      "module.encoder_k.layer1.0.downsample.1.running_mean\n",
      "module.encoder_k.layer1.0.downsample.1.running_var\n",
      "module.encoder_k.layer1.0.downsample.1.num_batches_tracked\n",
      "module.encoder_k.layer1.1.conv1.weight\n",
      "module.encoder_k.layer1.1.bn1.weight\n",
      "module.encoder_k.layer1.1.bn1.bias\n",
      "module.encoder_k.layer1.1.bn1.running_mean\n",
      "module.encoder_k.layer1.1.bn1.running_var\n",
      "module.encoder_k.layer1.1.bn1.num_batches_tracked\n",
      "module.encoder_k.layer1.1.conv2.weight\n",
      "module.encoder_k.layer1.1.bn2.weight\n",
      "module.encoder_k.layer1.1.bn2.bias\n",
      "module.encoder_k.layer1.1.bn2.running_mean\n",
      "module.encoder_k.layer1.1.bn2.running_var\n",
      "module.encoder_k.layer1.1.bn2.num_batches_tracked\n",
      "module.encoder_k.layer1.1.conv3.weight\n",
      "module.encoder_k.layer1.1.bn3.weight\n",
      "module.encoder_k.layer1.1.bn3.bias\n",
      "module.encoder_k.layer1.1.bn3.running_mean\n",
      "module.encoder_k.layer1.1.bn3.running_var\n",
      "module.encoder_k.layer1.1.bn3.num_batches_tracked\n",
      "module.encoder_k.layer1.2.conv1.weight\n",
      "module.encoder_k.layer1.2.bn1.weight\n",
      "module.encoder_k.layer1.2.bn1.bias\n",
      "module.encoder_k.layer1.2.bn1.running_mean\n",
      "module.encoder_k.layer1.2.bn1.running_var\n",
      "module.encoder_k.layer1.2.bn1.num_batches_tracked\n",
      "module.encoder_k.layer1.2.conv2.weight\n",
      "module.encoder_k.layer1.2.bn2.weight\n",
      "module.encoder_k.layer1.2.bn2.bias\n",
      "module.encoder_k.layer1.2.bn2.running_mean\n",
      "module.encoder_k.layer1.2.bn2.running_var\n",
      "module.encoder_k.layer1.2.bn2.num_batches_tracked\n",
      "module.encoder_k.layer1.2.conv3.weight\n",
      "module.encoder_k.layer1.2.bn3.weight\n",
      "module.encoder_k.layer1.2.bn3.bias\n",
      "module.encoder_k.layer1.2.bn3.running_mean\n",
      "module.encoder_k.layer1.2.bn3.running_var\n",
      "module.encoder_k.layer1.2.bn3.num_batches_tracked\n",
      "module.encoder_k.layer2.0.conv1.weight\n",
      "module.encoder_k.layer2.0.bn1.weight\n",
      "module.encoder_k.layer2.0.bn1.bias\n",
      "module.encoder_k.layer2.0.bn1.running_mean\n",
      "module.encoder_k.layer2.0.bn1.running_var\n",
      "module.encoder_k.layer2.0.bn1.num_batches_tracked\n",
      "module.encoder_k.layer2.0.conv2.weight\n",
      "module.encoder_k.layer2.0.bn2.weight\n",
      "module.encoder_k.layer2.0.bn2.bias\n",
      "module.encoder_k.layer2.0.bn2.running_mean\n",
      "module.encoder_k.layer2.0.bn2.running_var\n",
      "module.encoder_k.layer2.0.bn2.num_batches_tracked\n",
      "module.encoder_k.layer2.0.conv3.weight\n",
      "module.encoder_k.layer2.0.bn3.weight\n",
      "module.encoder_k.layer2.0.bn3.bias\n",
      "module.encoder_k.layer2.0.bn3.running_mean\n",
      "module.encoder_k.layer2.0.bn3.running_var\n",
      "module.encoder_k.layer2.0.bn3.num_batches_tracked\n",
      "module.encoder_k.layer2.0.downsample.0.weight\n",
      "module.encoder_k.layer2.0.downsample.1.weight\n",
      "module.encoder_k.layer2.0.downsample.1.bias\n",
      "module.encoder_k.layer2.0.downsample.1.running_mean\n",
      "module.encoder_k.layer2.0.downsample.1.running_var\n",
      "module.encoder_k.layer2.0.downsample.1.num_batches_tracked\n",
      "module.encoder_k.layer2.1.conv1.weight\n",
      "module.encoder_k.layer2.1.bn1.weight\n",
      "module.encoder_k.layer2.1.bn1.bias\n",
      "module.encoder_k.layer2.1.bn1.running_mean\n",
      "module.encoder_k.layer2.1.bn1.running_var\n",
      "module.encoder_k.layer2.1.bn1.num_batches_tracked\n",
      "module.encoder_k.layer2.1.conv2.weight\n",
      "module.encoder_k.layer2.1.bn2.weight\n",
      "module.encoder_k.layer2.1.bn2.bias\n",
      "module.encoder_k.layer2.1.bn2.running_mean\n",
      "module.encoder_k.layer2.1.bn2.running_var\n",
      "module.encoder_k.layer2.1.bn2.num_batches_tracked\n",
      "module.encoder_k.layer2.1.conv3.weight\n",
      "module.encoder_k.layer2.1.bn3.weight\n",
      "module.encoder_k.layer2.1.bn3.bias\n",
      "module.encoder_k.layer2.1.bn3.running_mean\n",
      "module.encoder_k.layer2.1.bn3.running_var\n",
      "module.encoder_k.layer2.1.bn3.num_batches_tracked\n",
      "module.encoder_k.layer2.2.conv1.weight\n",
      "module.encoder_k.layer2.2.bn1.weight\n",
      "module.encoder_k.layer2.2.bn1.bias\n",
      "module.encoder_k.layer2.2.bn1.running_mean\n",
      "module.encoder_k.layer2.2.bn1.running_var\n",
      "module.encoder_k.layer2.2.bn1.num_batches_tracked\n",
      "module.encoder_k.layer2.2.conv2.weight\n",
      "module.encoder_k.layer2.2.bn2.weight\n",
      "module.encoder_k.layer2.2.bn2.bias\n",
      "module.encoder_k.layer2.2.bn2.running_mean\n",
      "module.encoder_k.layer2.2.bn2.running_var\n",
      "module.encoder_k.layer2.2.bn2.num_batches_tracked\n",
      "module.encoder_k.layer2.2.conv3.weight\n",
      "module.encoder_k.layer2.2.bn3.weight\n",
      "module.encoder_k.layer2.2.bn3.bias\n",
      "module.encoder_k.layer2.2.bn3.running_mean\n",
      "module.encoder_k.layer2.2.bn3.running_var\n",
      "module.encoder_k.layer2.2.bn3.num_batches_tracked\n",
      "module.encoder_k.layer2.3.conv1.weight\n",
      "module.encoder_k.layer2.3.bn1.weight\n",
      "module.encoder_k.layer2.3.bn1.bias\n",
      "module.encoder_k.layer2.3.bn1.running_mean\n",
      "module.encoder_k.layer2.3.bn1.running_var\n",
      "module.encoder_k.layer2.3.bn1.num_batches_tracked\n",
      "module.encoder_k.layer2.3.conv2.weight\n",
      "module.encoder_k.layer2.3.bn2.weight\n",
      "module.encoder_k.layer2.3.bn2.bias\n",
      "module.encoder_k.layer2.3.bn2.running_mean\n",
      "module.encoder_k.layer2.3.bn2.running_var\n",
      "module.encoder_k.layer2.3.bn2.num_batches_tracked\n",
      "module.encoder_k.layer2.3.conv3.weight\n",
      "module.encoder_k.layer2.3.bn3.weight\n",
      "module.encoder_k.layer2.3.bn3.bias\n",
      "module.encoder_k.layer2.3.bn3.running_mean\n",
      "module.encoder_k.layer2.3.bn3.running_var\n",
      "module.encoder_k.layer2.3.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.0.conv1.weight\n",
      "module.encoder_k.layer3.0.bn1.weight\n",
      "module.encoder_k.layer3.0.bn1.bias\n",
      "module.encoder_k.layer3.0.bn1.running_mean\n",
      "module.encoder_k.layer3.0.bn1.running_var\n",
      "module.encoder_k.layer3.0.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.0.conv2.weight\n",
      "module.encoder_k.layer3.0.bn2.weight\n",
      "module.encoder_k.layer3.0.bn2.bias\n",
      "module.encoder_k.layer3.0.bn2.running_mean\n",
      "module.encoder_k.layer3.0.bn2.running_var\n",
      "module.encoder_k.layer3.0.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.0.conv3.weight\n",
      "module.encoder_k.layer3.0.bn3.weight\n",
      "module.encoder_k.layer3.0.bn3.bias\n",
      "module.encoder_k.layer3.0.bn3.running_mean\n",
      "module.encoder_k.layer3.0.bn3.running_var\n",
      "module.encoder_k.layer3.0.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.0.downsample.0.weight\n",
      "module.encoder_k.layer3.0.downsample.1.weight\n",
      "module.encoder_k.layer3.0.downsample.1.bias\n",
      "module.encoder_k.layer3.0.downsample.1.running_mean\n",
      "module.encoder_k.layer3.0.downsample.1.running_var\n",
      "module.encoder_k.layer3.0.downsample.1.num_batches_tracked\n",
      "module.encoder_k.layer3.1.conv1.weight\n",
      "module.encoder_k.layer3.1.bn1.weight\n",
      "module.encoder_k.layer3.1.bn1.bias\n",
      "module.encoder_k.layer3.1.bn1.running_mean\n",
      "module.encoder_k.layer3.1.bn1.running_var\n",
      "module.encoder_k.layer3.1.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.1.conv2.weight\n",
      "module.encoder_k.layer3.1.bn2.weight\n",
      "module.encoder_k.layer3.1.bn2.bias\n",
      "module.encoder_k.layer3.1.bn2.running_mean\n",
      "module.encoder_k.layer3.1.bn2.running_var\n",
      "module.encoder_k.layer3.1.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.1.conv3.weight\n",
      "module.encoder_k.layer3.1.bn3.weight\n",
      "module.encoder_k.layer3.1.bn3.bias\n",
      "module.encoder_k.layer3.1.bn3.running_mean\n",
      "module.encoder_k.layer3.1.bn3.running_var\n",
      "module.encoder_k.layer3.1.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.2.conv1.weight\n",
      "module.encoder_k.layer3.2.bn1.weight\n",
      "module.encoder_k.layer3.2.bn1.bias\n",
      "module.encoder_k.layer3.2.bn1.running_mean\n",
      "module.encoder_k.layer3.2.bn1.running_var\n",
      "module.encoder_k.layer3.2.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.2.conv2.weight\n",
      "module.encoder_k.layer3.2.bn2.weight\n",
      "module.encoder_k.layer3.2.bn2.bias\n",
      "module.encoder_k.layer3.2.bn2.running_mean\n",
      "module.encoder_k.layer3.2.bn2.running_var\n",
      "module.encoder_k.layer3.2.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.2.conv3.weight\n",
      "module.encoder_k.layer3.2.bn3.weight\n",
      "module.encoder_k.layer3.2.bn3.bias\n",
      "module.encoder_k.layer3.2.bn3.running_mean\n",
      "module.encoder_k.layer3.2.bn3.running_var\n",
      "module.encoder_k.layer3.2.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.3.conv1.weight\n",
      "module.encoder_k.layer3.3.bn1.weight\n",
      "module.encoder_k.layer3.3.bn1.bias\n",
      "module.encoder_k.layer3.3.bn1.running_mean\n",
      "module.encoder_k.layer3.3.bn1.running_var\n",
      "module.encoder_k.layer3.3.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.3.conv2.weight\n",
      "module.encoder_k.layer3.3.bn2.weight\n",
      "module.encoder_k.layer3.3.bn2.bias\n",
      "module.encoder_k.layer3.3.bn2.running_mean\n",
      "module.encoder_k.layer3.3.bn2.running_var\n",
      "module.encoder_k.layer3.3.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.3.conv3.weight\n",
      "module.encoder_k.layer3.3.bn3.weight\n",
      "module.encoder_k.layer3.3.bn3.bias\n",
      "module.encoder_k.layer3.3.bn3.running_mean\n",
      "module.encoder_k.layer3.3.bn3.running_var\n",
      "module.encoder_k.layer3.3.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.4.conv1.weight\n",
      "module.encoder_k.layer3.4.bn1.weight\n",
      "module.encoder_k.layer3.4.bn1.bias\n",
      "module.encoder_k.layer3.4.bn1.running_mean\n",
      "module.encoder_k.layer3.4.bn1.running_var\n",
      "module.encoder_k.layer3.4.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.4.conv2.weight\n",
      "module.encoder_k.layer3.4.bn2.weight\n",
      "module.encoder_k.layer3.4.bn2.bias\n",
      "module.encoder_k.layer3.4.bn2.running_mean\n",
      "module.encoder_k.layer3.4.bn2.running_var\n",
      "module.encoder_k.layer3.4.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.4.conv3.weight\n",
      "module.encoder_k.layer3.4.bn3.weight\n",
      "module.encoder_k.layer3.4.bn3.bias\n",
      "module.encoder_k.layer3.4.bn3.running_mean\n",
      "module.encoder_k.layer3.4.bn3.running_var\n",
      "module.encoder_k.layer3.4.bn3.num_batches_tracked\n",
      "module.encoder_k.layer3.5.conv1.weight\n",
      "module.encoder_k.layer3.5.bn1.weight\n",
      "module.encoder_k.layer3.5.bn1.bias\n",
      "module.encoder_k.layer3.5.bn1.running_mean\n",
      "module.encoder_k.layer3.5.bn1.running_var\n",
      "module.encoder_k.layer3.5.bn1.num_batches_tracked\n",
      "module.encoder_k.layer3.5.conv2.weight\n",
      "module.encoder_k.layer3.5.bn2.weight\n",
      "module.encoder_k.layer3.5.bn2.bias\n",
      "module.encoder_k.layer3.5.bn2.running_mean\n",
      "module.encoder_k.layer3.5.bn2.running_var\n",
      "module.encoder_k.layer3.5.bn2.num_batches_tracked\n",
      "module.encoder_k.layer3.5.conv3.weight\n",
      "module.encoder_k.layer3.5.bn3.weight\n",
      "module.encoder_k.layer3.5.bn3.bias\n",
      "module.encoder_k.layer3.5.bn3.running_mean\n",
      "module.encoder_k.layer3.5.bn3.running_var\n",
      "module.encoder_k.layer3.5.bn3.num_batches_tracked\n",
      "module.encoder_k.layer4.0.conv1.weight\n",
      "module.encoder_k.layer4.0.bn1.weight\n",
      "module.encoder_k.layer4.0.bn1.bias\n",
      "module.encoder_k.layer4.0.bn1.running_mean\n",
      "module.encoder_k.layer4.0.bn1.running_var\n",
      "module.encoder_k.layer4.0.bn1.num_batches_tracked\n",
      "module.encoder_k.layer4.0.conv2.weight\n",
      "module.encoder_k.layer4.0.bn2.weight\n",
      "module.encoder_k.layer4.0.bn2.bias\n",
      "module.encoder_k.layer4.0.bn2.running_mean\n",
      "module.encoder_k.layer4.0.bn2.running_var\n",
      "module.encoder_k.layer4.0.bn2.num_batches_tracked\n",
      "module.encoder_k.layer4.0.conv3.weight\n",
      "module.encoder_k.layer4.0.bn3.weight\n",
      "module.encoder_k.layer4.0.bn3.bias\n",
      "module.encoder_k.layer4.0.bn3.running_mean\n",
      "module.encoder_k.layer4.0.bn3.running_var\n",
      "module.encoder_k.layer4.0.bn3.num_batches_tracked\n",
      "module.encoder_k.layer4.0.downsample.0.weight\n",
      "module.encoder_k.layer4.0.downsample.1.weight\n",
      "module.encoder_k.layer4.0.downsample.1.bias\n",
      "module.encoder_k.layer4.0.downsample.1.running_mean\n",
      "module.encoder_k.layer4.0.downsample.1.running_var\n",
      "module.encoder_k.layer4.0.downsample.1.num_batches_tracked\n",
      "module.encoder_k.layer4.1.conv1.weight\n",
      "module.encoder_k.layer4.1.bn1.weight\n",
      "module.encoder_k.layer4.1.bn1.bias\n",
      "module.encoder_k.layer4.1.bn1.running_mean\n",
      "module.encoder_k.layer4.1.bn1.running_var\n",
      "module.encoder_k.layer4.1.bn1.num_batches_tracked\n",
      "module.encoder_k.layer4.1.conv2.weight\n",
      "module.encoder_k.layer4.1.bn2.weight\n",
      "module.encoder_k.layer4.1.bn2.bias\n",
      "module.encoder_k.layer4.1.bn2.running_mean\n",
      "module.encoder_k.layer4.1.bn2.running_var\n",
      "module.encoder_k.layer4.1.bn2.num_batches_tracked\n",
      "module.encoder_k.layer4.1.conv3.weight\n",
      "module.encoder_k.layer4.1.bn3.weight\n",
      "module.encoder_k.layer4.1.bn3.bias\n",
      "module.encoder_k.layer4.1.bn3.running_mean\n",
      "module.encoder_k.layer4.1.bn3.running_var\n",
      "module.encoder_k.layer4.1.bn3.num_batches_tracked\n",
      "module.encoder_k.layer4.2.conv1.weight\n",
      "module.encoder_k.layer4.2.bn1.weight\n",
      "module.encoder_k.layer4.2.bn1.bias\n",
      "module.encoder_k.layer4.2.bn1.running_mean\n",
      "module.encoder_k.layer4.2.bn1.running_var\n",
      "module.encoder_k.layer4.2.bn1.num_batches_tracked\n",
      "module.encoder_k.layer4.2.conv2.weight\n",
      "module.encoder_k.layer4.2.bn2.weight\n",
      "module.encoder_k.layer4.2.bn2.bias\n",
      "module.encoder_k.layer4.2.bn2.running_mean\n",
      "module.encoder_k.layer4.2.bn2.running_var\n",
      "module.encoder_k.layer4.2.bn2.num_batches_tracked\n",
      "module.encoder_k.layer4.2.conv3.weight\n",
      "module.encoder_k.layer4.2.bn3.weight\n",
      "module.encoder_k.layer4.2.bn3.bias\n",
      "module.encoder_k.layer4.2.bn3.running_mean\n",
      "module.encoder_k.layer4.2.bn3.running_var\n",
      "module.encoder_k.layer4.2.bn3.num_batches_tracked\n",
      "module.encoder_k.fc.0.weight\n",
      "module.encoder_k.fc.0.bias\n",
      "module.encoder_k.fc.2.weight\n",
      "module.encoder_k.fc.2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MoCo(\n",
       "  (model): ModuleDict(\n",
       "    (encoder): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): Identity()\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (moco): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_k): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take in the augment from hyperopt and return some augmentations, in teh way that we want them. \n",
    "def policy_decoder(augment, num_policy, num_op):\n",
    "    op_list = augment_list(False)\n",
    "    policies = []\n",
    "    for i in range(num_policy):\n",
    "        ops = []\n",
    "        for j in range(num_op):\n",
    "            op_idx = augment['policy_%d_%d' % (i, j)]\n",
    "            op_prob = augment['prob_%d_%d' % (i, j)]\n",
    "            op_level = augment['level_%d_%d' % (i, j)]\n",
    "            ops.append((op_list[op_idx][0].__name__, op_prob, op_level))\n",
    "        policies.append(ops)\n",
    "    return policies\n",
    "\n",
    "def find_model(name, fold, epochs=750, basepath=\"/userdata/smetzger/all_deepul_files/ckpts\"):\n",
    "    \"\"\"\n",
    "    name = model name\n",
    "    fold = which fold of the data to find. \n",
    "    epochs = how many epochs to load the checkpoint at (e.g. 750)\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in os.listdir(basepath):\n",
    "        if name in str(file) and 'fold_%d' %fold in str(file):\n",
    "            if str(file).endswith(str(epochs-1) + '.tar'): \n",
    "                return os.path.join(basepath, file)\n",
    "            \n",
    "    print(\"COULDNT FIND MODEL\")\n",
    "    assert True==False # just throw an error. \n",
    "\n",
    "def load_model(cv_fold, loss_type): \n",
    "    model = models.__dict__[args.arch]()\n",
    "    # CIFAR 10 mod\n",
    "    \n",
    "    \n",
    "    if args.dataid ==\"cifar10\":\n",
    "    # use the layer the SIMCLR authors used for cifar10 input conv, checked all padding/strides too.\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1,1), padding=(1,1), bias=False)\n",
    "        model.maxpool = nn.Identity()\n",
    "\n",
    "    # freeze all layers but the last fc\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            param.requires_grad = False\n",
    "    # init the fc layer\n",
    "    if args.dataid == \"cifar10\":\n",
    "#         print('before change', model.fc)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10) # note this is for cifar 10.\n",
    "#         print(model.fc)\n",
    "\n",
    "\n",
    "    if loss_type == 'supervised': \n",
    "        savefile = os.path.join(args.checkpoint_fp, \n",
    "                                \"{}_lincls_best.tar\".format(args.checkpoints[cv_fold]))\n",
    "    elif loss_type == 'rotation': \n",
    "        savefile = os.path.join(args.checkpoint_fp, \n",
    "                                 \"{}_lincls_best_rotation.tar\".format(args.checkpoints[cv_fold]))\n",
    "\n",
    "    elif loss_type == 'icl': \n",
    "        heads = {}\n",
    "        if not args.nomoco:\n",
    "            heads[\"moco\"] = {\n",
    "            \"num_classes\": args.moco_dim\n",
    "        }\n",
    "        \n",
    "        # Build a moco model. \n",
    "        model = moco.builder.MoCo(\n",
    "            models.__dict__[args.arch],\n",
    "            K=args.moco_k, m=args.moco_m, T=args.moco_t, mlp=args.mlp, dataid=args.dataid,\n",
    "            multitask_heads=heads\n",
    "        )\n",
    "        savefile = find_model(args.checkpoints[cv_fold], cv_fold)\n",
    "          \n",
    "            \n",
    "    print('savefile', savefile)\n",
    "\n",
    "    ckpt = torch.load(savefile, map_location=\"cpu\")\n",
    "    \n",
    "    state_dict = ckpt['state_dict']\n",
    "    \n",
    "    for k in list(state_dict.keys()):\n",
    "        # retain only encoder_q up to before the embedding layer\n",
    "        print(k)\n",
    "        if k.startswith('module'):\n",
    "            # remove prefix\n",
    "            \n",
    "            state_dict[k[len(\"module.\"):]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "            \n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    # Load the FC layer and append it to the end. \n",
    "    \n",
    "load_model(0, args.loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def rotate_images(images):\n",
    "    nimages = images.shape[0]\n",
    "    n_rot_images = 4*nimages\n",
    "\n",
    "    # rotate images all 4 ways at once\n",
    "    rotated_images = torch.zeros([n_rot_images, images.shape[1], images.shape[2], images.shape[3]]).cuda()\n",
    "    rot_classes = torch.zeros([n_rot_images]).long().cuda()\n",
    "\n",
    "    rotated_images[:nimages] = images\n",
    "    # rotate 90\n",
    "    rotated_images[nimages:2*nimages] = images.flip(3).transpose(2,3)\n",
    "    rot_classes[nimages:2*nimages] = 1\n",
    "    # rotate 180\n",
    "    rotated_images[2*nimages:3*nimages] = images.flip(3).flip(2)\n",
    "    rot_classes[2*nimages:3*nimages] = 2\n",
    "    # rotate 270\n",
    "    rotated_images[3*nimages:4*nimages] = images.transpose(2,3).flip(3)\n",
    "    rot_classes[3*nimages:4*nimages] = 3\n",
    "\n",
    "    return rotated_images, rot_classes\n",
    "\n",
    "\n",
    "def eval_augmentations(config): \n",
    "    augment = config\n",
    "    print('called', augment)\n",
    "    augmentations = policy_decoder(augment, augment['num_policy'], augment['num_op'])\n",
    "    # Load the model from wandb. \n",
    "    fold = augment['cv_fold']\n",
    "    ckpt = args.checkpoint_fp + 'fold_%d.tar' %(fold)\n",
    "\n",
    "    model = load_model(cv_fold, args.loss).cuda()\n",
    "    model.eval()\n",
    "    loaders = []\n",
    "\n",
    "    \n",
    "    for _ in range(args.num_policy): #TODO: \n",
    "        _, validloader = get_dataloaders(augmentations, 128, kfold=fold)\n",
    "        loaders.append(iter(validloader))\n",
    "        del _\n",
    "\n",
    "           \n",
    "        \n",
    "    metrics = Accumulator()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    try: \n",
    "        with torch.no_grad(): \n",
    "            while True: \n",
    "                losses = []\n",
    "                corrects = []\n",
    "\n",
    "                for loader in loaders:\n",
    "                    \n",
    "                    if not args.loss == 'icl':\n",
    "                        \n",
    "                        \n",
    "                        data, label = next(loader)\n",
    "                        data = data.cuda()\n",
    "                        label = label.cuda()\n",
    "\n",
    "                        if args.loss == 'supervised':\n",
    "                            pred = model(data)\n",
    "\n",
    "                        if args.loss ==\"rotation\":\n",
    "                            rotated_images, label = rotate_images(data)\n",
    "                            pred = model(rotated_images)  \n",
    "                            \n",
    "                    else: \n",
    "                        \n",
    "                        images, _ = next(loader)\n",
    "                        images[0] = images[0].cuda()\n",
    "                        images[1] = images[1].cuda()\n",
    "                        \n",
    "                        pred, label =model(head=\"moco\", im_q=images[1], im_k=images[1])\n",
    "                        \n",
    "                        \n",
    "\n",
    "\n",
    "                    loss = loss_fn(pred, label)\n",
    "                    losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                    _, pred = pred.topk(1, 1, True, True)\n",
    "                    pred = pred.t()\n",
    "                    correct = pred.eq(label.view(1, -1).expand_as(pred)).detach().cpu().numpy()\n",
    "                    corrects.append(correct)\n",
    "\n",
    "                    del loss, correct, pred, data, label\n",
    "\n",
    "                losses = np.concatenate(losses)\n",
    "                losses_min = np.min(losses, axis=0).squeeze()\n",
    "\n",
    "                corrects = np.concatenate(corrects)\n",
    "                corrects_max = np.max(corrects, axis=0).squeeze()\n",
    "                metrics.add_dict({ \n",
    "                    'minus_loss': -1*np.sum(losses_min),\n",
    "                    'correct': np.sum(corrects_max),\n",
    "                    'cnt': len(corrects_max)})\n",
    "                del corrects, corrects_max\n",
    "\n",
    "    \n",
    "    except StopIteration: \n",
    "        pass\n",
    "\n",
    "    del model\n",
    "    metrics = metrics/'cnt'\n",
    "    # reporter(minus_loss=metrics['minus_loss'], top_1_valid=metrics['correct'], done=True)\n",
    "    tune.track.log(top_1_valid=metrics['correct'])\n",
    "    print(metrics['correct'])\n",
    "    return metrics['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:27,907\tERROR worker.py:682 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 45.1/1005.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/28 CPUs, 1/3 GPUs, 0.0/783.4 GiB heap, 0.0/128.52 GiB objects<br>Result logdir: /home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0<br>Number of trials: 3 (2 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  level_0_0</th><th style=\"text-align: right;\">  level_0_1</th><th style=\"text-align: right;\">  level_1_0</th><th style=\"text-align: right;\">  level_1_1</th><th style=\"text-align: right;\">  level_2_0</th><th style=\"text-align: right;\">  level_2_1</th><th style=\"text-align: right;\">  level_3_0</th><th style=\"text-align: right;\">  level_3_1</th><th style=\"text-align: right;\">  level_4_0</th><th style=\"text-align: right;\">  level_4_1</th><th style=\"text-align: right;\">  policy_0_0</th><th style=\"text-align: right;\">  policy_0_1</th><th style=\"text-align: right;\">  policy_1_0</th><th style=\"text-align: right;\">  policy_1_1</th><th style=\"text-align: right;\">  policy_2_0</th><th style=\"text-align: right;\">  policy_2_1</th><th style=\"text-align: right;\">  policy_3_0</th><th style=\"text-align: right;\">  policy_3_1</th><th style=\"text-align: right;\">  policy_4_0</th><th style=\"text-align: right;\">  policy_4_1</th><th style=\"text-align: right;\">  prob_0_0</th><th style=\"text-align: right;\">  prob_0_1</th><th style=\"text-align: right;\">  prob_1_0</th><th style=\"text-align: right;\">  prob_1_1</th><th style=\"text-align: right;\">  prob_2_0</th><th style=\"text-align: right;\">  prob_2_1</th><th style=\"text-align: right;\">  prob_3_0</th><th style=\"text-align: right;\">  prob_3_1</th><th style=\"text-align: right;\">  prob_4_0</th><th style=\"text-align: right;\">  prob_4_1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>eval_augmentations_0aeeb1a0</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.891689</td><td style=\"text-align: right;\">   0.516835</td><td style=\"text-align: right;\">  0.0988878</td><td style=\"text-align: right;\">  0.716001 </td><td style=\"text-align: right;\">   0.670601</td><td style=\"text-align: right;\">   0.913903</td><td style=\"text-align: right;\">   0.746636</td><td style=\"text-align: right;\">   0.287322</td><td style=\"text-align: right;\">  0.858395 </td><td style=\"text-align: right;\">   0.645032</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">  0.570681</td><td style=\"text-align: right;\">  0.806012</td><td style=\"text-align: right;\">  0.515561</td><td style=\"text-align: right;\"> 0.968723 </td><td style=\"text-align: right;\"> 0.029672 </td><td style=\"text-align: right;\">  0.516068</td><td style=\"text-align: right;\">  0.524743</td><td style=\"text-align: right;\">  0.290879</td><td style=\"text-align: right;\">  0.138073</td><td style=\"text-align: right;\"> 0.0233805</td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a1</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.631581</td><td style=\"text-align: right;\">   0.521527</td><td style=\"text-align: right;\">  0.0156443</td><td style=\"text-align: right;\">  0.651538 </td><td style=\"text-align: right;\">   0.612477</td><td style=\"text-align: right;\">   0.270808</td><td style=\"text-align: right;\">   0.341872</td><td style=\"text-align: right;\">   0.683883</td><td style=\"text-align: right;\">  0.0418649</td><td style=\"text-align: right;\">   0.899953</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">  0.37315 </td><td style=\"text-align: right;\">  0.761998</td><td style=\"text-align: right;\">  0.375297</td><td style=\"text-align: right;\"> 0.859738 </td><td style=\"text-align: right;\"> 0.397689 </td><td style=\"text-align: right;\">  0.163353</td><td style=\"text-align: right;\">  0.702301</td><td style=\"text-align: right;\">  0.349159</td><td style=\"text-align: right;\">  0.832994</td><td style=\"text-align: right;\"> 0.632567 </td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a2</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">   0.463282</td><td style=\"text-align: right;\">   0.632681</td><td style=\"text-align: right;\">  0.178962 </td><td style=\"text-align: right;\">  0.0213005</td><td style=\"text-align: right;\">   0.941215</td><td style=\"text-align: right;\">   0.375126</td><td style=\"text-align: right;\">   0.294871</td><td style=\"text-align: right;\">   0.593662</td><td style=\"text-align: right;\">  0.675092 </td><td style=\"text-align: right;\">   0.451026</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">  0.877157</td><td style=\"text-align: right;\">  0.610719</td><td style=\"text-align: right;\">  0.336996</td><td style=\"text-align: right;\"> 0.0652798</td><td style=\"text-align: right;\"> 0.0363297</td><td style=\"text-align: right;\">  0.821609</td><td style=\"text-align: right;\">  0.774398</td><td style=\"text-align: right;\">  0.528632</td><td style=\"text-align: right;\">  0.797881</td><td style=\"text-align: right;\"> 0.767929 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:29,568\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID 39db908a0100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n",
      "2020-04-30 21:34:29,570\tERROR trial_runner.py:521 -- Trial eval_augmentations_0aeeb1a0: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308020, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m 2020-04-30 21:34:29,560\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308020)\u001b[0m ModuleNotFoundError: No module named 'moco'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:30,463\tERROR trial_runner.py:521 -- Trial eval_augmentations_0aeeb1a1: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308019, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n",
      "2020-04-30 21:34:30,467\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID a9ccc7780100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m 2020-04-30 21:34:30,457\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m ModuleNotFoundError: No module named 'moco'\n",
      "\u001b[2m\u001b[36m(pid=308019)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:31,372\tERROR trial_runner.py:521 -- Trial eval_augmentations_0aeeb1a2: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308016, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n",
      "2020-04-30 21:34:31,378\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID b8f327c70100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m 2020-04-30 21:34:31,366\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m ModuleNotFoundError: No module named 'moco'\n",
      "\u001b[2m\u001b[36m(pid=308016)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:32,893\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID 585895140100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n",
      "2020-04-30 21:34:32,895\tERROR trial_runner.py:521 -- Trial eval_augmentations_0aeeb1a3: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308264, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m 2020-04-30 21:34:32,889\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308264)\u001b[0m ModuleNotFoundError: No module named 'moco'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:33,797\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID 06254a390100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n",
      "2020-04-30 21:34:33,801\tERROR trial_runner.py:521 -- Trial eval_augmentations_0bf83864: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308269, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m 2020-04-30 21:34:33,790\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308269)\u001b[0m ModuleNotFoundError: No module named 'moco'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 45.1/1005.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/28 CPUs, 2/3 GPUs, 0.0/783.4 GiB heap, 0.0/128.52 GiB objects<br>Result logdir: /home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0<br>Number of trials: 7 (5 ERROR, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  level_0_0</th><th style=\"text-align: right;\">  level_0_1</th><th style=\"text-align: right;\">  level_1_0</th><th style=\"text-align: right;\">  level_1_1</th><th style=\"text-align: right;\">  level_2_0</th><th style=\"text-align: right;\">  level_2_1</th><th style=\"text-align: right;\">  level_3_0</th><th style=\"text-align: right;\">  level_3_1</th><th style=\"text-align: right;\">  level_4_0</th><th style=\"text-align: right;\">  level_4_1</th><th style=\"text-align: right;\">  policy_0_0</th><th style=\"text-align: right;\">  policy_0_1</th><th style=\"text-align: right;\">  policy_1_0</th><th style=\"text-align: right;\">  policy_1_1</th><th style=\"text-align: right;\">  policy_2_0</th><th style=\"text-align: right;\">  policy_2_1</th><th style=\"text-align: right;\">  policy_3_0</th><th style=\"text-align: right;\">  policy_3_1</th><th style=\"text-align: right;\">  policy_4_0</th><th style=\"text-align: right;\">  policy_4_1</th><th style=\"text-align: right;\">  prob_0_0</th><th style=\"text-align: right;\">  prob_0_1</th><th style=\"text-align: right;\">  prob_1_0</th><th style=\"text-align: right;\">  prob_1_1</th><th style=\"text-align: right;\">  prob_2_0</th><th style=\"text-align: right;\">  prob_2_1</th><th style=\"text-align: right;\">  prob_3_0</th><th style=\"text-align: right;\">  prob_3_1</th><th style=\"text-align: right;\">  prob_4_0</th><th style=\"text-align: right;\">  prob_4_1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>eval_augmentations_0aeeb1a0</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">   0.891689</td><td style=\"text-align: right;\">   0.516835</td><td style=\"text-align: right;\">  0.0988878</td><td style=\"text-align: right;\">  0.716001 </td><td style=\"text-align: right;\">   0.670601</td><td style=\"text-align: right;\">   0.913903</td><td style=\"text-align: right;\">   0.746636</td><td style=\"text-align: right;\">   0.287322</td><td style=\"text-align: right;\">  0.858395 </td><td style=\"text-align: right;\">   0.645032</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\"> 0.570681 </td><td style=\"text-align: right;\">  0.806012</td><td style=\"text-align: right;\">  0.515561</td><td style=\"text-align: right;\"> 0.968723 </td><td style=\"text-align: right;\"> 0.029672 </td><td style=\"text-align: right;\"> 0.516068 </td><td style=\"text-align: right;\"> 0.524743 </td><td style=\"text-align: right;\">  0.290879</td><td style=\"text-align: right;\">  0.138073</td><td style=\"text-align: right;\"> 0.0233805</td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a1</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">   0.631581</td><td style=\"text-align: right;\">   0.521527</td><td style=\"text-align: right;\">  0.0156443</td><td style=\"text-align: right;\">  0.651538 </td><td style=\"text-align: right;\">   0.612477</td><td style=\"text-align: right;\">   0.270808</td><td style=\"text-align: right;\">   0.341872</td><td style=\"text-align: right;\">   0.683883</td><td style=\"text-align: right;\">  0.0418649</td><td style=\"text-align: right;\">   0.899953</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\"> 0.37315  </td><td style=\"text-align: right;\">  0.761998</td><td style=\"text-align: right;\">  0.375297</td><td style=\"text-align: right;\"> 0.859738 </td><td style=\"text-align: right;\"> 0.397689 </td><td style=\"text-align: right;\"> 0.163353 </td><td style=\"text-align: right;\"> 0.702301 </td><td style=\"text-align: right;\">  0.349159</td><td style=\"text-align: right;\">  0.832994</td><td style=\"text-align: right;\"> 0.632567 </td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a2</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">   0.463282</td><td style=\"text-align: right;\">   0.632681</td><td style=\"text-align: right;\">  0.178962 </td><td style=\"text-align: right;\">  0.0213005</td><td style=\"text-align: right;\">   0.941215</td><td style=\"text-align: right;\">   0.375126</td><td style=\"text-align: right;\">   0.294871</td><td style=\"text-align: right;\">   0.593662</td><td style=\"text-align: right;\">  0.675092 </td><td style=\"text-align: right;\">   0.451026</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">          14</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\"> 0.877157 </td><td style=\"text-align: right;\">  0.610719</td><td style=\"text-align: right;\">  0.336996</td><td style=\"text-align: right;\"> 0.0652798</td><td style=\"text-align: right;\"> 0.0363297</td><td style=\"text-align: right;\"> 0.821609 </td><td style=\"text-align: right;\"> 0.774398 </td><td style=\"text-align: right;\">  0.528632</td><td style=\"text-align: right;\">  0.797881</td><td style=\"text-align: right;\"> 0.767929 </td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a3</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">   0.142307</td><td style=\"text-align: right;\">   0.85673 </td><td style=\"text-align: right;\">  0.857963 </td><td style=\"text-align: right;\">  0.534094 </td><td style=\"text-align: right;\">   0.362011</td><td style=\"text-align: right;\">   0.824546</td><td style=\"text-align: right;\">   0.743187</td><td style=\"text-align: right;\">   0.64521 </td><td style=\"text-align: right;\">  0.738087 </td><td style=\"text-align: right;\">   0.81599 </td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\"> 0.0542832</td><td style=\"text-align: right;\">  0.4779  </td><td style=\"text-align: right;\">  0.400025</td><td style=\"text-align: right;\"> 0.590496 </td><td style=\"text-align: right;\"> 0.727583 </td><td style=\"text-align: right;\"> 0.898847 </td><td style=\"text-align: right;\"> 0.0649214</td><td style=\"text-align: right;\">  0.34086 </td><td style=\"text-align: right;\">  0.306033</td><td style=\"text-align: right;\"> 0.284798 </td></tr>\n",
       "<tr><td>eval_augmentations_0bf83864</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">   0.215079</td><td style=\"text-align: right;\">   0.754348</td><td style=\"text-align: right;\">  0.400496 </td><td style=\"text-align: right;\">  0.15322  </td><td style=\"text-align: right;\">   0.9052  </td><td style=\"text-align: right;\">   0.731558</td><td style=\"text-align: right;\">   0.880802</td><td style=\"text-align: right;\">   0.491227</td><td style=\"text-align: right;\">  0.0758903</td><td style=\"text-align: right;\">   0.866517</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\"> 0.652622 </td><td style=\"text-align: right;\">  0.523277</td><td style=\"text-align: right;\">  0.140954</td><td style=\"text-align: right;\"> 0.577139 </td><td style=\"text-align: right;\"> 0.358705 </td><td style=\"text-align: right;\"> 0.694886 </td><td style=\"text-align: right;\"> 0.77792  </td><td style=\"text-align: right;\">  0.385104</td><td style=\"text-align: right;\">  0.582895</td><td style=\"text-align: right;\"> 0.135443 </td></tr>\n",
       "<tr><td>eval_augmentations_0bf83865</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.977974</td><td style=\"text-align: right;\">   0.114978</td><td style=\"text-align: right;\">  0.748711 </td><td style=\"text-align: right;\">  0.115495 </td><td style=\"text-align: right;\">   0.160212</td><td style=\"text-align: right;\">   0.13234 </td><td style=\"text-align: right;\">   0.512708</td><td style=\"text-align: right;\">   0.975556</td><td style=\"text-align: right;\">  0.199981 </td><td style=\"text-align: right;\">   0.690361</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\"> 0.575615 </td><td style=\"text-align: right;\">  0.222744</td><td style=\"text-align: right;\">  0.283399</td><td style=\"text-align: right;\"> 0.329435 </td><td style=\"text-align: right;\"> 0.122853 </td><td style=\"text-align: right;\"> 0.0144634</td><td style=\"text-align: right;\"> 0.398227 </td><td style=\"text-align: right;\">  0.775999</td><td style=\"text-align: right;\">  0.887415</td><td style=\"text-align: right;\"> 0.849703 </td></tr>\n",
       "<tr><td>eval_augmentations_0d082afc</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">   0.55231 </td><td style=\"text-align: right;\">   0.099467</td><td style=\"text-align: right;\">  0.748532 </td><td style=\"text-align: right;\">  0.669685 </td><td style=\"text-align: right;\">   0.843469</td><td style=\"text-align: right;\">   0.362132</td><td style=\"text-align: right;\">   0.864542</td><td style=\"text-align: right;\">   0.103858</td><td style=\"text-align: right;\">  0.827119 </td><td style=\"text-align: right;\">   0.994967</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          12</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          13</td><td style=\"text-align: right;\">          11</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\"> 0.499328 </td><td style=\"text-align: right;\">  0.857623</td><td style=\"text-align: right;\">  0.942258</td><td style=\"text-align: right;\"> 0.428382 </td><td style=\"text-align: right;\"> 0.0016557</td><td style=\"text-align: right;\"> 0.708979 </td><td style=\"text-align: right;\"> 0.180947 </td><td style=\"text-align: right;\">  0.425538</td><td style=\"text-align: right;\">  0.682965</td><td style=\"text-align: right;\"> 0.36761  </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 5<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>eval_augmentations_0aeeb1a0</td><td style=\"text-align: right;\">           1</td><td>/home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0/eval_augmentations_1_cv_fold=0,level_0_0=0.89169,level_0_1=0.51684,level_1_0=0.098888,level_1_1=0.716,level_2_0=0.6706,level_2_1=0_2020-04-30_21-34-28ksttp10_/error.txt</td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a1</td><td style=\"text-align: right;\">           1</td><td>/home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0/eval_augmentations_2_cv_fold=0,level_0_0=0.63158,level_0_1=0.52153,level_1_0=0.015644,level_1_1=0.65154,level_2_0=0.61248,level_2__2020-04-30_21-34-28f72b10to/error.txt</td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a2</td><td style=\"text-align: right;\">           1</td><td>/home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0/eval_augmentations_3_cv_fold=0,level_0_0=0.46328,level_0_1=0.63268,level_1_0=0.17896,level_1_1=0.0213,level_2_0=0.94121,level_2_1=_2020-04-30_21-34-28hxhrvsh9/error.txt</td></tr>\n",
       "<tr><td>eval_augmentations_0aeeb1a3</td><td style=\"text-align: right;\">           1</td><td>/home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0/eval_augmentations_4_cv_fold=0,level_0_0=0.14231,level_0_1=0.85673,level_1_0=0.85796,level_1_1=0.53409,level_2_0=0.36201,level_2_1_2020-04-30_21-34-29pphp5gdg/error.txt</td></tr>\n",
       "<tr><td>eval_augmentations_0bf83864</td><td style=\"text-align: right;\">           1</td><td>/home/smetzger/ray_results/slm_rotnet_search_cifar10_fold_0/eval_augmentations_5_cv_fold=0,level_0_0=0.21508,level_0_1=0.75435,level_1_0=0.4005,level_1_1=0.15322,level_2_0=0.9052,level_2_1=0_2020-04-30_21-34-300evw0bf6/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 21:34:34,638\tERROR trial_runner.py:521 -- Trial eval_augmentations_0bf83865: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/worker.py\", line 1513, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::TemporaryActor.__init__()\u001b[39m (pid=308263, ip=169.230.190.118)\n",
      "  File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "RuntimeError: The actor with name WrappedTrackFunc failed to be imported, and so cannot execute this method.\n",
      "2020-04-30 21:34:34,644\tWARNING worker.py:1072 -- Failed to unpickle actor class 'WrappedTrackFunc' for actor ID d3640eed0100. Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "    actor_class = pickle.loads(pickled_class)\n",
      "  File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "    __import__(name)\n",
      "ModuleNotFoundError: No module named 'moco'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m 2020-04-30 21:34:34,632\tERROR function_manager.py:497 -- Failed to load actor class WrappedTrackFunc.\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/function_manager.py\", line 495, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m   File \"/userdata/smetzger/gim/lib/python3.6/site-packages/ray/cloudpickle/cloudpickle.py\", line 1136, in subimport\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m ModuleNotFoundError: No module named 'moco'\n",
      "\u001b[2m\u001b[36m(pid=308263)\u001b[0m <class 'autoaug_scripts.Augmentation'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b55202c7f033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             },\n\u001b[1;32m     46\u001b[0m             \u001b[0mreturn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training_iteration'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m         \u001b[0mresults_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_trial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mstart_trial\u001b[0;34m(self, trial, checkpoint)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_commit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAbortTrialExecution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             logger.exception(\"Trial %s: Error starting runner, aborting!\",\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36m_start_trial\u001b[0;34m(self, trial, checkpoint, runner)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrunner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mreuse_allowed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_remote_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_allowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36m_setup_remote_runner\u001b[0;34m(self, trial, reuse_allowed)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_remote_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_allowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# We checkpoint metadata here to try mitigating logdir duplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_checkpoint_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/trial.py\u001b[0m in \u001b[0;36minit_logger\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mloggers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 sync_function=self.sync_to_driver_fn)\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logdir, trial, loggers, sync_function)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_syncer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnifiedLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logdir, trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_cls_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 logger.warning(\"Could not instantiate %s: %s.\", cls.__name__,\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logdir, trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXPR_RESULT_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/userdata/smetzger/gim/lib/python3.6/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36mupdate_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 cls=_SafeFallbackEncoder)\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mconfig_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXPR_PARAM_PICKLE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_pkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ops = augment_list(False) # Get the default augmentation set. \n",
    "# Define the space of our augmentations. \n",
    "space = {}\n",
    "for i in range(args.num_policy): \n",
    "    for j in range(args.num_op):\n",
    "        space['policy_%d_%d' %(i,j)]  = hp.choice('policy_%d_%d' %(i, j), list(range(0, len(ops))))\n",
    "        space['prob_%d_%d' %(i, j)] = hp.uniform('prob_%d_%d' %(i, j), 0.0, 1.0)\n",
    "        space['level_%d_%d' %(i, j)] = hp.uniform('level_%d_%d' %(i, j), 0.0, 1.0)\n",
    "\n",
    "final_policy_set = []\n",
    "reward_attr = 'top_1_valid' # TODO: let this be whatever we want. \n",
    "object_store_memory = int(0.6 * ray.utils.get_system_memory() // 10 ** 9 * 10 ** 9)\n",
    "ray.init(num_gpus=3, ignore_reinit_error=True, \n",
    "    num_cpus=28\n",
    "    )\n",
    "# ray.init(num_gpus=1, memory=200*1024*1024*100, object_store_memory=200*1024*1024*50)\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "cv_num = 5\n",
    "num_result_per_cv = 10\n",
    "\n",
    "for _ in range(2): \n",
    "    for cv_fold in range(cv_num): \n",
    "        name = \"slm_rotnet_search_%s_fold_%d\" %(args.dataid, cv_fold)\n",
    "        hyperopt_search=HyperOptSearch(space, \n",
    "            max_concurrent=3,\n",
    "            metric=reward_attr,\n",
    "            mode='max')\n",
    "\n",
    "\n",
    "        results = tune.run(\n",
    "            eval_augmentations, \n",
    "            name=name,\n",
    "            num_samples=200,\n",
    "            resources_per_trial={\n",
    "                \"gpu\": 1\n",
    "            },\n",
    "            search_alg=hyperopt_search,\n",
    "            verbose=2,\n",
    "            config = { \n",
    "                'num_op': args.num_op, \n",
    "                'num_policy': args.num_policy, \n",
    "                'cv_fold': cv_fold\n",
    "            },\n",
    "            return_trials=True,\n",
    "            stop={'training_iteration': 1},\n",
    "        )\n",
    "        results_copy = results\n",
    "        results = [x for x in results if x.last_result is not None]\n",
    "        results = sorted(results, key= lambda x: x.last_result[reward_attr], reverse=True)\n",
    "\n",
    "        for result in results[:num_result_per_cv]: \n",
    "            final_policy = policy_decoder(result.config, args.num_policy, args.num_op)\n",
    "            final_policy_set.extend(final_policy)\n",
    "\n",
    "        print(final_policy)\n",
    "print(final_policy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_augmentations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
