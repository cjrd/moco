{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE is based of fastautoagument code here \n",
    "\n",
    "# https://github.com/kakaobrain/fast-autoaugment/blob/master/FastAutoAugment/search.py\n",
    "\n",
    "# With some changes to make it more efficient for us. \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # TODO KILL THIS. \n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ray \n",
    "from ray.tune.trial import Trial\n",
    "from ray.tune.trial_runner import TrialRunner\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from hyperopt import hp\n",
    "from ray.tune import register_trainable, run_experiments\n",
    "import wandb\n",
    "import argparse\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import slm_utils.get_faa_transforms\n",
    "from slm_utils.get_faa_transforms import Augmentation, augment_list\n",
    "import moco.loader\n",
    "import moco.builder\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to use for our moco model. \n",
    "\n",
    "# argparser.add('--checkpoint_fp', type=str, help='base file path where everything is stored.')\n",
    "# argparser.add('-checkpoints' , '--list', nargs='+', help='The list of the checkpoint codes, in order by cv fold')\n",
    "# # example: search.py -checkpoints rdElg fxrZE IJu2W vnhKs esdq2\n",
    "\n",
    "# argparser.add('--data', type=str, help=\"Where the data directory is\")\n",
    "# argparser.add('--dataid', type=str, default='cifar10', help=\"imagenet or cifar\")\n",
    " \n",
    "# # Arguments for FAA.  \n",
    "# parser.add_argument('--num-op', type=int, default=2, help=\"number of operations per subpolicy.\")\n",
    "# parser.add_argument('--num-policy', type=int, default=5, help=\"number of subpolicies in each policy\")\n",
    "# parser.add_argument('--num-search', type=int, default=200, help=\"number of hyperopt iterations to run.\")\n",
    "# parser.add_argument('--smoke-test', action='store_true', help=\"quick test of our search\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "# FOR DEBUG\n",
    "class Args:\n",
    "    checkpoints = ['fxrZE', 'lJu2W', 'rdEIg', 'esdq2' ,'vnhKs']\n",
    "    checkpoint_fp = '/userdata/smetzger/all_deepul_files/ckpts'\n",
    "    data = '/userdata/smetzger/data/cifar_10/'\n",
    "    num_op = 2\n",
    "    num_policy=5\n",
    "    num_search = 200\n",
    "    dataid = 'cifar10'\n",
    "    cv_ratio=1.0\n",
    "    smoke_test=True\n",
    "    resume=False\n",
    "    arch = 'resnet50'\n",
    "    distributed=False\n",
    "    workers=8\n",
    "args=Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.transforms import Compose\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "random_mirror = True\n",
    "\n",
    "\n",
    "def ShearX(img, v):  # [-0.3, 0.3]\n",
    "    assert -0.3 <= v <= 0.3\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v):  # [-0.3, 0.3]\n",
    "    assert -0.3 <= v <= 0.3\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert -0.45 <= v <= 0.45\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[0]\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert -0.45 <= v <= 0.45\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[1]\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def TranslateXAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert 0 <= v <= 10\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateYAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert 0 <= v <= 10\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def Rotate(img, v):  # [-30, 30]\n",
    "    assert -30 <= v <= 30\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def AutoContrast(img, _):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Invert(img, _):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Equalize(img, _):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Flip(img, _):  # not from the paper\n",
    "    return PIL.ImageOps.mirror(img)\n",
    "\n",
    "\n",
    "def Solarize(img, v):  # [0, 256]\n",
    "    assert 0 <= v <= 256\n",
    "    return PIL.ImageOps.solarize(img, v)\n",
    "\n",
    "\n",
    "def Posterize(img, v):  # [4, 8]\n",
    "    assert 4 <= v <= 8\n",
    "    v = int(v)\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Posterize2(img, v):  # [0, 4]\n",
    "    assert 0 <= v <= 4\n",
    "    v = int(v)\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Contrast(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Brightness(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
    "    assert 0.0 <= v <= 0.2\n",
    "    if v <= 0.:\n",
    "        return img\n",
    "\n",
    "    v = v * img.size[0]\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
    "    # assert 0 <= v <= 20\n",
    "    if v < 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(w)\n",
    "    y0 = np.random.uniform(h)\n",
    "\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = min(w, x0 + v)\n",
    "    y1 = min(h, y0 + v)\n",
    "\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    color = (125, 123, 114)\n",
    "    # color = (0, 0, 0)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def SamplePairing(imgs):  # [0, 0.4]\n",
    "    def f(img1, v):\n",
    "        i = np.random.choice(len(imgs))\n",
    "        img2 = PIL.Image.fromarray(imgs[i])\n",
    "        return PIL.Image.blend(img1, img2, v)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def augment_list(for_autoaug=True):  # 16 oeprations and their ranges\n",
    "    l = [\n",
    "        (ShearX, -0.3, 0.3),  # 0\n",
    "        (ShearY, -0.3, 0.3),  # 1\n",
    "        (TranslateX, -0.45, 0.45),  # 2\n",
    "        (TranslateY, -0.45, 0.45),  # 3\n",
    "        (Rotate, -30, 30),  # 4\n",
    "        (AutoContrast, 0, 1),  # 5\n",
    "        (Invert, 0, 1),  # 6\n",
    "        (Equalize, 0, 1),  # 7\n",
    "        (Solarize, 0, 256),  # 8\n",
    "        (Posterize, 4, 8),  # 9\n",
    "        (Contrast, 0.1, 1.9),  # 10\n",
    "        (Color, 0.1, 1.9),  # 11\n",
    "        (Brightness, 0.1, 1.9),  # 12\n",
    "        (Sharpness, 0.1, 1.9),  # 13\n",
    "        (Cutout, 0, 0.2),  # 14\n",
    "        # (SamplePairing(imgs), 0, 0.4),  # 15\n",
    "    ]\n",
    "    if for_autoaug:\n",
    "        l += [\n",
    "            (CutoutAbs, 0, 20),  # compatible with auto-augment\n",
    "            (Posterize2, 0, 4),  # 9\n",
    "            (TranslateXAbs, 0, 10),  # 9\n",
    "            (TranslateYAbs, 0, 10),  # 9\n",
    "        ]\n",
    "    return l\n",
    "\n",
    "\n",
    "augment_dict = {fn.__name__: (fn, v1, v2) for fn, v1, v2 in augment_list()}\n",
    "\n",
    "\n",
    "def get_augment(name):\n",
    "    return augment_dict[name]\n",
    "\n",
    "\n",
    "def apply_augment(img, name, level):\n",
    "    augment_fn, low, high = get_augment(name)\n",
    "    return augment_fn(img.copy(), level * (high - low) + low)\n",
    "\n",
    "\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = torch.Tensor(eigval)\n",
    "        self.eigvec = torch.Tensor(eigvec)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone() \\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "class Augmentation(object):\n",
    "    def __init__(self, policies):\n",
    "        self.policies = policies\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for _ in range(1):\n",
    "            policy = random.choice(self.policies)\n",
    "            for name, pr, level in policy:\n",
    "                if random.random() > pr:\n",
    "                    continue\n",
    "                img = apply_augment(img, name, level)\n",
    "        return img\n",
    "\n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "from collections import defaultdict\n",
    "class Accumulator:\n",
    "    def __init__(self):\n",
    "        self.metrics = defaultdict(lambda: 0.)\n",
    "\n",
    "    def add(self, key, value):\n",
    "        self.metrics[key] += value\n",
    "\n",
    "    def add_dict(self, dict):\n",
    "        for key, value in dict.items():\n",
    "            self.add(key, value)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.metrics[item]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.metrics[key] = value\n",
    "\n",
    "    def get_dict(self):\n",
    "        return copy.deepcopy(dict(self.metrics))\n",
    "\n",
    "    def items(self):\n",
    "        return self.metrics.items()\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(dict(self.metrics))\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        newone = Accumulator()\n",
    "        for key, value in self.items():\n",
    "            if isinstance(other, str):\n",
    "                if other != key:\n",
    "                    newone[key] = value / self[other]\n",
    "                else:\n",
    "                    newone[key] = value\n",
    "            else:\n",
    "                newone[key] = value / other\n",
    "        return newone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how we load our dataloaders. \n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "\n",
    "def get_dataloaders(augmentations, batch=128, kfold=0, get_train=False):\n",
    "\n",
    "    \"\"\"\n",
    "    input: augmentations: the list of the augmentations you want applied to the data. \n",
    "    batch = batchsize, \n",
    "    kfold, which fold you want to look at (0, 1,2 3, or 4)\n",
    "    get_train, whether or not you want the train data. Use this when loading the data to train linear classifiers, \n",
    "    slash when you're loading the final classifier. \n",
    "    \"\"\"\n",
    "    if args.dataid == \"imagenet\":\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            traindir,\n",
    "            transformations)\n",
    "\n",
    "        # TODO: add imagenet transforms etc. \n",
    "    elif args.dataid == \"cifar10\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "\n",
    "        transform_train.transforms.insert(0, Augmentation(augmentations))\n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Support for the following dataset is not yet implemented: {}\".format(args.dataid))\n",
    "\n",
    "    if get_train: \n",
    "        train_dataset = torchvision.datasets.CIFAR10(args.data,\n",
    "                                                     transform=transform_train,\n",
    "                                                     download=True)\n",
    "\n",
    "    val_dataset = torchvision.datasets.CIFAR10(args.data, transform=transform_test, \n",
    "        download=True)\n",
    "\n",
    "    if get_train: \n",
    "        torch.manual_seed(1337)\n",
    "        lengths = [len(train_dataset)//5]*5\n",
    "        folds = torch.utils.data.random_split(train_dataset, lengths)\n",
    "        folds.pop(kfold)\n",
    "        train_dataset = torch.utils.data.ConcatDataset(folds)\n",
    "\n",
    "\n",
    "    torch.manual_seed(1337)\n",
    "    lengths = [len(val_dataset)//5]*5\n",
    "    folds = torch.utils.data.random_split(val_dataset, lengths)\n",
    "    val_dataset = folds[kfold]\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset) #TODO: is this necessary? \n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler=None\n",
    "\n",
    "    if get_train: \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch, shuffle=(train_sampler is None),\n",
    "            num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    val_loader= torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch, shuffle=False,\n",
    "        #TODO restore pin memory\n",
    "        num_workers=args.workers, pin_memory=False , sampler =val_sampler, drop_last=False\n",
    "    )\n",
    "\n",
    "    if not get_train: \n",
    "        train_loader = None\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Take in the augment from hyperopt and return some augmentations, in teh way that we want them. \n",
    "def policy_decoder(augment, num_policy, num_op):\n",
    "    op_list = augment_list(False)\n",
    "    policies = []\n",
    "    for i in range(num_policy):\n",
    "        ops = []\n",
    "        for j in range(num_op):\n",
    "            op_idx = augment['policy_%d_%d' % (i, j)]\n",
    "            op_prob = augment['prob_%d_%d' % (i, j)]\n",
    "            op_level = augment['level_%d_%d' % (i, j)]\n",
    "            ops.append((op_list[op_idx][0].__name__, op_prob, op_level))\n",
    "        policies.append(ops)\n",
    "    return policies\n",
    "\n",
    "def load_base_model(cv_fold): \n",
    "    \n",
    "    if args.pretrained:\n",
    "        if os.path.isfile(args.pretrained):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.pretrained))\n",
    "            checkpoint = torch.load(args.pretrained, map_location=\"cpu\")\n",
    "\n",
    "            # rename moco pre-trained keys\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            if checkpoint.get('id'):\n",
    "                # sync the ids for wandb\n",
    "                args.id = checkpoint['id']\n",
    "                name = args.id\n",
    "                wandb_resume = True\n",
    "            if checkpoint.get('name'):\n",
    "                name = checkpoint['name']\n",
    "\n",
    "            for k in list(state_dict.keys()):\n",
    "                # retain only encoder_q up to before the embedding layer\n",
    "                if k.startswith('module.model.encoder'):\n",
    "                    # remove prefix\n",
    "                    state_dict[k[len(\"module.model.encoder.\"):]] = state_dict[k]\n",
    "                # delete renamed or unused k\n",
    "                del state_dict[k]\n",
    "            args.start_epoch = 0\n",
    "            msg = model.load_state_dict(state_dict, strict=False)\n",
    "            assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}\n",
    "\n",
    "def load_model(cv_fold): \n",
    "    model = models.__dict__[args.arch]()\n",
    "    # CIFAR 10 mod\n",
    "    \n",
    "    \n",
    "    if args.dataid ==\"cifar10\":\n",
    "    # use the layer the SIMCLR authors used for cifar10 input conv, checked all padding/strides too.\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1,1), padding=(1,1), bias=False)\n",
    "        model.maxpool = nn.Identity()\n",
    "\n",
    "    # freeze all layers but the last fc\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            param.requires_grad = False\n",
    "    # init the fc layer\n",
    "    if args.dataid == \"cifar10\":\n",
    "#         print('before change', model.fc)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10) # note this is for cifar 10.\n",
    "#         print(model.fc)\n",
    "\n",
    "\n",
    "    savefile = os.path.join(args.checkpoint_fp, \n",
    "                            \"{}_lincls_best.tar\".format(args.checkpoints[cv_fold]))\n",
    "\n",
    "    ckpt = torch.load(savefile, map_location=\"cpu\")\n",
    "    \n",
    "    state_dict = ckpt['state_dict']\n",
    "    \n",
    "    for k in list(state_dict.keys()):\n",
    "        # retain only encoder_q up to before the embedding layer\n",
    "        \n",
    "        if k.startswith('module'):\n",
    "            # remove prefix\n",
    "            \n",
    "            state_dict[k[len(\"module.\"):]] = state_dict[k]\n",
    "            del state_dict[k]\n",
    "            \n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    # Load the FC layer and append it to the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_augmentations(augment, reporter): \n",
    "    augmentations = policy_decoder(augment, augment['num_policy'], augment['num_op'])\n",
    "    # Load the model from wandb. \n",
    "    fold = augment['cv_fold']\n",
    "    ckpt = args.checkpoint_fp + 'fold_%d.tar' %(fold)\n",
    "\n",
    "    model = load_model(cv_fold).cuda()\n",
    "\n",
    "\n",
    "\n",
    "    loaders = []\n",
    "#     TODO: Undo this\n",
    "#     for _ in range(augment['num_policy']): \n",
    "    for _ in range(2):\n",
    "        _, validloader = get_dataloaders(augmentations, 128, kfold=fold)\n",
    "        loaders.append(iter(validloader))\n",
    "        del _\n",
    "\n",
    "\n",
    "    metrics = Accumulator()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    try: \n",
    "        while True: \n",
    "            losses = []\n",
    "            corrects = []\n",
    "\n",
    "            for loader in loaders:\n",
    "                data, label = next(loader)\n",
    "                data = data.cuda()\n",
    "                label = label.cuda()\n",
    "                pred = model(data)\n",
    "\n",
    "                loss = loss_fn(pred, label)\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                _, pred = pred.topk(1, 1, True, True)\n",
    "                pred = pred.t()\n",
    "                correct = pred.eq(label.view(1, -1).expand_as(pred)).detach().cpu().numpy()\n",
    "                corrects.append(correct)\n",
    "\n",
    "                del loss, correct, pred, data, label\n",
    "\n",
    "            losses = np.concatenate(losses)\n",
    "            losses_min = np.min(losses, axis=0).squeeze()\n",
    "\n",
    "            corrects = np.concatenate(corrects)\n",
    "            corrects_max = np.max(corrects, axis=0).squeeze()\n",
    "            metrics.add_dict({ \n",
    "                'minus_loss': -1*np.sum(losses_min),\n",
    "                'correct': np.sum(corrects_max),\n",
    "                'cnt': len(corrects_max)})\n",
    "            del corrects, corrects_max\n",
    "    \n",
    "    except StopIteration: \n",
    "        pass\n",
    "\n",
    "    del model\n",
    "    metrics = metrics/'cnt'\n",
    "    reporter(minus_loss=metrics['minus_loss'], top_1_valid=metrics['correct'], done=True)\n",
    "    return metrics['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = augment_list(False) # Get the default augmentation set. \n",
    "# Define the space of our augmentations. \n",
    "space = {}\n",
    "\n",
    "for i in range(args.num_policy): \n",
    "    for j in range(args.num_op):\n",
    "        space['policy_%d_%d' %(i,j)]  = hp.choice('policy_%d_%d' %(i, j), list(range(0, len(ops))))\n",
    "        space['prob_%d_%d' %(i, j)] = hp.uniform('prob_%d_%d' %(i, j), 0.0, 1.0)\n",
    "        space['level_%d_%d' %(i, j)] = hp.uniform('level_%d_%d' %(i, j), 0.0, 1.0)\n",
    "\n",
    "final_policy_set = []\n",
    "reward_attr = 'top_1_valid' # TODO: let this be whatever we want. \n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1)\n",
    "\n",
    "from ray.tune import register_trainable, run_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_num = 5\n",
    "num_result_per_cv = 10\n",
    "\n",
    "for _ in range(1): \n",
    "    for cv_fold in range(cv_num): \n",
    "        name = \"search_%s_fold_%d_ratio%.1f\" %(args.dataid, cv_fold, args.cv_ratio)\n",
    "        print(name)\n",
    "        ray.tune.register_trainable(name, eval_augmentations)\n",
    "        algo=HyperOptSearch(space, max_concurrent=1, reward_attr=reward_attr)\n",
    "\n",
    "        exp_config = { \n",
    "            'run': name,\n",
    "            'num_samples': 4 if args.smoke_test else args.num_search,\n",
    "            'resources_per_trial': {'gpu': 1}, \n",
    "            'stop': {'training_iteration': args.num_policy}, # So we eval 25 times???? \n",
    "            'config': { \n",
    "            'num_op': args.num_op, \n",
    "            'num_policy': args.num_policy, \n",
    "            'cv_fold': cv_fold\n",
    "            }\n",
    "        }\n",
    "\n",
    "        results = ray.tune.run_experiments({\"exp1\":exp_config}, search_alg=algo, scheduler=None, verbose=0, queue_trials=True, \n",
    "            resume=args.resume)\n",
    "\n",
    "        results = [x for x in results if x.last_result is not None]\n",
    "        results = sorted(results, key= lambda x: x.last_result[reward_attr], reverse=True)\n",
    "\n",
    "        for result in results[:num_result_per_cv]: \n",
    "            final_policy = policy_decoder(result.config, args.num_policy, args.num_op)\n",
    "            final_policy_set.extend(final_policy)\n",
    "\n",
    "print(final_policy_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
